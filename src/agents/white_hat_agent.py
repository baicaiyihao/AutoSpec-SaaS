"""
White Hat Agent - ç™½å¸½é»‘å®¢è§’è‰² Agent

æ ¸å¿ƒèŒè´£ï¼š
1. åƒçœŸæ­£çš„å®‰å…¨ç ”ç©¶å‘˜ä¸€æ ·æ€è€ƒæ¼æ´åˆ©ç”¨
2. åˆ†ææ¼æ´çš„å…¥å£ç‚¹ã€åˆ©ç”¨é“¾ã€æ”»å‡»å½±å“
3. è¿‡æ»¤æ‰"ç†è®ºæ€§æ¼æ´"ï¼ˆæ— æ³•å®é™…åˆ©ç”¨çš„ï¼‰
4. ç”Ÿæˆå¯éªŒè¯çš„æ¼æ´æŠ¥å‘Š

è®¾è®¡ç†å¿µï¼š
- å¦‚æœæ— æ³•è¯´æ¸…æ¥šåˆ©ç”¨é“¾ï¼Œå°±ä¸èƒ½ç¡®è®¤æ˜¯çœŸå®æ¼æ´
- åˆ©ç”¨ RAG çŸ¥è¯†åº“ä¸­çš„çœŸå®æ¡ˆä¾‹æ¥è¾…åŠ©åˆ†æ
- è¾“å‡ºå¿…é¡»åŒ…å«ï¼šå…¥å£ç‚¹ã€æ”»å‡»è·¯å¾„ã€å‰ç½®æ¡ä»¶ã€æœ€ç»ˆå½±å“
- æœ€ç»ˆç›®æ ‡ï¼šå°†"ç–‘ä¼¼æ¼æ´"è½¬åŒ–ä¸º"å¯éªŒè¯æ¼æ´"æˆ–"è¯¯æŠ¥"

å·¥ä½œæµç¨‹ï¼š
    æ¼æ´æ‰«æç»“æœ (SecurityScanner)
            â†“
    WhiteHatAgent.analyze()
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. RAGæ£€ç´¢ç±»ä¼¼å†å²æ¼æ´            â”‚
    â”‚ 2. å…¥å£ç‚¹åˆ†æ                     â”‚
    â”‚ 3. åˆ©ç”¨é“¾æ„å»º                     â”‚
    â”‚ 4. å‰ç½®æ¡ä»¶è¯†åˆ«                   â”‚
    â”‚ 5. å½±å“è¯„ä¼°                       â”‚
    â”‚ 6. å¯åˆ©ç”¨æ€§åˆ¤æ–­                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    æ¼æ´éªŒè¯æŠ¥å‘Š (ExploitVerificationReport)
"""

import json
import re
import time
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Any
from enum import Enum

from src.llm_providers import LLMProviderFactory, LLMConfig, ProviderType
from src.utils.json_parser import robust_parse_json, extract_fields_regex, WHITEHAT_FIELD_PATTERNS
from src.security.exploit_analyzer import (
    ExploitChain, ExploitChainAnalyzer,
    ExploitGoal, ExploitComplexity, ExploitConfidence,
    EntryPoint, AttackStep, Precondition, ExploitImpact
)
from src.prompts.exploit_prompts import (
    WHITE_HAT_VERIFICATION_PROMPT,  # ğŸ”¥ ç»Ÿä¸€çš„å·¥å…·è¾…åŠ©åˆ©ç”¨é“¾åˆ†æ
    build_rag_query,
    format_rag_results,
    get_exploit_hints,
)

# ğŸ”¥ v2.5.7: å®Œå…¨ç§»é™¤å®‰å…¨çŸ¥è¯†æ³¨å…¥
# - Phase 3 (VerifierAgent) å·²å¤„ç† Move æœºåˆ¶ç›¸å…³çš„è¯¯æŠ¥è¿‡æ»¤
# - RAG å†å²æ¼æ´æ¨¡å¼é€šè¿‡ _retrieve_similar_cases() å•ç‹¬æ£€ç´¢
# - åˆ é™¤äº† _get_relevant_security_knowledge() æ–¹æ³•
# - èŠ‚çœ ~5-8K tokens/å®¡è®¡


class VerificationStatus(Enum):
    """æ¼æ´éªŒè¯çŠ¶æ€"""
    VERIFIED = "verified"           # å·²éªŒè¯å¯åˆ©ç”¨
    LIKELY = "likely"               # å¾ˆå¯èƒ½å¯åˆ©ç”¨
    NEEDS_REVIEW = "needs_review"   # éœ€è¦äººå·¥å®¡æŸ¥
    THEORETICAL = "theoretical"     # ä»…ç†è®ºä¸Šå­˜åœ¨
    FALSE_POSITIVE = "false_positive"  # è¯¯æŠ¥


@dataclass
class ExploitVerificationReport:
    """æ¼æ´éªŒè¯æŠ¥å‘Š - GitHub Security Advisory æ ¼å¼"""
    vulnerability_id: str
    vulnerability_type: str
    severity: str

    # éªŒè¯ç»“æœ
    status: VerificationStatus
    confidence_score: float  # 0-100
    exploitability_score: float  # 0-10

    # === æ–°å¢: GitHub Security Advisory æ ¼å¼å­—æ®µ ===
    advisory: Dict = field(default_factory=dict)  # title, severity, vulnerability_type, affected_component
    vulnerability_summary: str = ""  # æ¼æ´æ‘˜è¦
    technical_details: Dict = field(default_factory=dict)  # root_cause, vulnerable_code, vulnerable_function
    attack_scenario: List[str] = field(default_factory=list)  # æ”»å‡»æ­¥éª¤åˆ—è¡¨
    poc_code: str = ""  # PoC ä»£ç 
    impact_assessment: Dict = field(default_factory=dict)  # impact_type, affected_users, max_loss, attack_cost, attack_complexity
    recommended_mitigation: List[str] = field(default_factory=list)  # ä¿®å¤å»ºè®®
    blocking_factors: List[str] = field(default_factory=list)  # é˜»æ–­å› ç´ ï¼ˆä¸å¯åˆ©ç”¨æ—¶ï¼‰

    # åˆ©ç”¨é“¾åˆ†æ (ä¿ç•™å…¼å®¹)
    entry_point: Optional[Dict] = None
    attack_path: List[Dict] = field(default_factory=list)
    preconditions: List[Dict] = field(default_factory=list)
    impact: Optional[Dict] = None

    # å…³é”®ä¿¡æ¯
    one_liner_exploit: str = ""  # ä¸€å¥è¯æè¿°å¦‚ä½•åˆ©ç”¨
    why_exploitable: str = ""    # ä¸ºä»€ä¹ˆå¯ä»¥åˆ©ç”¨
    why_not_exploitable: Optional[str] = None  # ä¸ºä»€ä¹ˆä¸èƒ½åˆ©ç”¨ï¼ˆå¦‚æœæ˜¯ç†è®ºæ€§çš„ï¼‰

    # å‚è€ƒä¿¡æ¯
    similar_cases: List[str] = field(default_factory=list)  # ç±»ä¼¼çš„å†å²æ¡ˆä¾‹
    rag_sources: List[str] = field(default_factory=list)    # RAG æ£€ç´¢æ¥æº

    # ğŸ”¥ æ–°å¢ï¼šå®Œæ•´çš„ exploit ä»£ç å’Œæ€è·¯
    exploit_module_code: str = ""   # å®Œæ•´çš„ Move exploit æ¨¡å—ä»£ç 
    exploit_reasoning: str = ""     # åˆ©ç”¨æ€è·¯ï¼ˆç®­å¤´é“¾ï¼‰

    # åŸå§‹æ•°æ®
    raw_vulnerability: Dict = field(default_factory=dict)
    analysis_reasoning: str = ""   # åˆ†ææ¨ç†è¿‡ç¨‹

    def to_markdown(self) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
        status_emoji = {
            VerificationStatus.VERIFIED: "ğŸ”´",
            VerificationStatus.LIKELY: "ğŸŸ ",
            VerificationStatus.NEEDS_REVIEW: "ğŸŸ¡",
            VerificationStatus.THEORETICAL: "âšª",
            VerificationStatus.FALSE_POSITIVE: "ğŸŸ¢",
        }

        lines = []
        lines.append(f"## {status_emoji.get(self.status, 'â“')} {self.vulnerability_id}")
        lines.append(f"**ç±»å‹**: {self.vulnerability_type}")
        lines.append(f"**ä¸¥é‡æ€§**: {self.severity}")
        lines.append(f"**éªŒè¯çŠ¶æ€**: {self.status.value.upper()}")
        lines.append(f"**å¯åˆ©ç”¨æ€§è¯„åˆ†**: {self.exploitability_score}/10")
        lines.append(f"**ç½®ä¿¡åº¦**: {self.confidence_score}%")
        lines.append("")

        # ä¸€å¥è¯åˆ©ç”¨æ–¹å¼
        lines.append("### åˆ©ç”¨æ–¹å¼")
        lines.append(f"> {self.one_liner_exploit}")
        lines.append("")

        # ä¸ºä»€ä¹ˆå¯ä»¥/ä¸èƒ½åˆ©ç”¨
        if self.status in [VerificationStatus.VERIFIED, VerificationStatus.LIKELY]:
            lines.append("### ä¸ºä»€ä¹ˆå¯ä»¥åˆ©ç”¨")
            lines.append(self.why_exploitable)
        elif self.why_not_exploitable:
            lines.append("### ä¸ºä»€ä¹ˆæ— æ³•ç¡®è®¤åˆ©ç”¨")
            lines.append(self.why_not_exploitable)
        lines.append("")

        # å…¥å£ç‚¹
        if self.entry_point:
            lines.append("### å…¥å£ç‚¹")
            lines.append(f"- **å‡½æ•°**: `{self.entry_point.get('function', 'Unknown')}`")
            lines.append(f"- **å¯è§æ€§**: {self.entry_point.get('visibility', 'Unknown')}")
            lines.append(f"- **è°ƒç”¨è€…è¦æ±‚**: {self.entry_point.get('caller_requirement', 'Unknown')}")
            lines.append("")

        # æ”»å‡»è·¯å¾„
        if self.attack_path:
            lines.append("### æ”»å‡»è·¯å¾„")
            for step in self.attack_path:
                step_num = step.get('step', step.get('step_number', '?'))
                lines.append(f"**Step {step_num}**: {step.get('action', '')}")
                if step.get('function_call'):
                    lines.append(f"  - è°ƒç”¨: `{step['function_call']}`")
                if step.get('purpose'):
                    lines.append(f"  - ç›®çš„: {step['purpose']}")
                if step.get('state_change'):
                    lines.append(f"  - çŠ¶æ€å˜åŒ–: {step['state_change']}")
            lines.append("")

        # å‰ç½®æ¡ä»¶
        if self.preconditions:
            lines.append("### å‰ç½®æ¡ä»¶")
            for pre in self.preconditions:
                difficulty = pre.get('difficulty', 'unknown')
                realistic = "âœ…" if pre.get('realistic', False) else "âš ï¸"
                lines.append(f"- {pre.get('condition', '')}")
                lines.append(f"  - è¾¾æˆæ–¹å¼: {pre.get('how_to_achieve', '')}")
                lines.append(f"  - éš¾åº¦: {difficulty} {realistic}")
            lines.append("")

        # å½±å“
        if self.impact:
            lines.append("### æ”»å‡»å½±å“")
            lines.append(f"- **ç›®æ ‡**: {self.impact.get('goal', 'Unknown')}")
            lines.append(f"- **æè¿°**: {self.impact.get('description', '')}")
            if self.impact.get('affected_parties'):
                lines.append(f"- **å—å½±å“æ–¹**: {', '.join(self.impact['affected_parties'])}")
            lines.append(f"- **æœ€å¤§æŸå¤±**: {self.impact.get('max_loss', 'Unknown')}")
            lines.append("")

        # ğŸ”¥ åˆ©ç”¨æ€è·¯
        if self.exploit_reasoning:
            lines.append("### åˆ©ç”¨æ€è·¯")
            lines.append(f"> {self.exploit_reasoning}")
            lines.append("")

        # ğŸ”¥ å®Œæ•´ Exploit ä»£ç 
        if self.exploit_module_code:
            lines.append("### Exploit ä»£ç  (PoC)")
            lines.append("```move")
            lines.append(self.exploit_module_code)
            lines.append("```")
            lines.append("")

        # ç±»ä¼¼æ¡ˆä¾‹
        if self.similar_cases:
            lines.append("### ç±»ä¼¼å†å²æ¡ˆä¾‹")
            for case in self.similar_cases[:5]:
                lines.append(f"- {case}")
            lines.append("")

        return "\n".join(lines)


class WhiteHatAgent:
    """
    ç™½å¸½é»‘å®¢ Agent

    ä»¥å®‰å…¨ç ”ç©¶å‘˜çš„è§†è§’åˆ†ææ¼æ´ï¼ŒéªŒè¯æ¼æ´çš„çœŸå®æ€§å’Œå¯åˆ©ç”¨æ€§ã€‚

    æ ¸å¿ƒèƒ½åŠ›ï¼š
    1. å…¥å£ç‚¹å‘ç° - æ‰¾åˆ°èƒ½å¤Ÿè§¦å‘æ¼æ´çš„ public/entry å‡½æ•°
    2. åˆ©ç”¨é“¾æ„å»º - ä»å…¥å£åˆ°æ¼æ´è§¦å‘çš„å®Œæ•´è·¯å¾„
    3. å‰ç½®æ¡ä»¶è¯†åˆ« - åˆ©ç”¨éœ€è¦æ»¡è¶³ä»€ä¹ˆæ¡ä»¶
    4. å½±å“è¯„ä¼° - æ”»å‡»æˆåŠŸåèƒ½è¾¾æˆä»€ä¹ˆç›®çš„
    5. å¯åˆ©ç”¨æ€§åˆ¤æ–­ - ç»¼åˆè¯„ä¼°æ˜¯å¦æ˜¯çœŸå®æ¼æ´

    ğŸ”¥ æ”¯æŒå·¥å…·è¾…åŠ©éªŒè¯æ¨¡å¼:
    å½“ use_tools=True æ—¶ï¼ŒAI å¯è‡ªä¸»è°ƒç”¨å·¥å…·æŸ¥çœ‹ä»£ç æ¥éªŒè¯æ¼æ´ã€‚

    Prompt å®šä¹‰åœ¨: src/prompts/exploit_prompts.py
    - WHITE_HAT_VERIFICATION_PROMPT: ç»Ÿä¸€çš„å·¥å…·è¾…åŠ©åˆ©ç”¨é“¾åˆ†æ
    """

    def __init__(self, rag_retriever=None, config=None, use_tools: bool = False):
        """
        Args:
            rag_retriever: RAG æ£€ç´¢å™¨ï¼Œç”¨äºæŸ¥è¯¢å†å²æ¼æ´æ¡ˆä¾‹
            config: AgentConfig é…ç½® (å¯é€‰)ï¼Œå¦‚æœä¸ä¼ åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            use_tools: æ˜¯å¦å¯ç”¨å·¥å…·è¾…åŠ©éªŒè¯æ¨¡å¼
        """
        import threading
        self.rag_retriever = rag_retriever
        self.config = config
        self.use_tools = use_tools  # ğŸ”¥ å·¥å…·è¾…åŠ©éªŒè¯æ¨¡å¼

        # æ ¹æ®é…ç½®åˆå§‹åŒ– LLM (config ç”± engine.py ä» PRESET ä¼ å…¥)
        self.llm = self._init_llm_from_config(config)

        # ğŸ”¥ LLM è°ƒç”¨é” - é˜²æ­¢åŒä¸€å®ä¾‹å¹¶å‘è°ƒç”¨ (çº¿ç¨‹é”ï¼Œå› ä¸º verify_vulnerability æ˜¯åŒæ­¥æ–¹æ³•)
        self._llm_lock = threading.Lock()

        self.exploit_analyzer = ExploitChainAnalyzer(
            rag_retriever=rag_retriever,
            llm_client=None  # æˆ‘ä»¬åœ¨è¿™ä¸ª agent ä¸­ç›´æ¥ä½¿ç”¨ LLM
        )

        # ğŸ”¥ å·¥å…·ç®± (ç”¨äºè‡ªä¸»æ£€ç´¢ä»£ç ä¸Šä¸‹æ–‡)
        self.toolkit = None

        # ğŸ”¥ v2.5.8: Token ä½¿ç”¨é‡ç»Ÿè®¡
        self._token_usage = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "call_count": 0
        }

        provider = config.provider if config else "deepseek"
        model = config.model if config else "deepseek-chat"
        tools_info = " [å·¥å…·è¾…åŠ©æ¨¡å¼]" if use_tools else ""
        print(f"ğŸ© [WhiteHatAgent] ç™½å¸½é»‘å®¢æ¨¡å¼å·²å¯åŠ¨ (using {provider}/{model}){tools_info}")

    def set_toolkit(self, toolkit):
        """
        è®¾ç½®å·¥å…·ç®±ï¼Œè®© Agent èƒ½å¤Ÿè‡ªä¸»æ£€ç´¢ä»£ç 

        Args:
            toolkit: AgentToolkit å®ä¾‹
        """
        self.toolkit = toolkit

    def _track_token_usage(self, usage: Dict[str, int]):
        """ğŸ”¥ v2.5.8: ç´¯åŠ  token ä½¿ç”¨é‡"""
        if usage:
            self._token_usage["prompt_tokens"] += usage.get("prompt_tokens", 0)
            self._token_usage["completion_tokens"] += usage.get("completion_tokens", 0)
            self._token_usage["total_tokens"] += usage.get("total_tokens", 0)
            self._token_usage["call_count"] += 1

    def get_token_usage(self) -> Dict[str, int]:
        """ğŸ”¥ v2.5.8: è·å– token ä½¿ç”¨é‡ç»Ÿè®¡"""
        return self._token_usage.copy()

    def reset_token_usage(self):
        """ğŸ”¥ v2.5.8: é‡ç½® token ä½¿ç”¨é‡ç»Ÿè®¡"""
        self._token_usage = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "call_count": 0
        }

    # ğŸ”¥ v2.5.7: ç§»é™¤ _get_relevant_security_knowledge() æ–¹æ³•
    # Phase 3 (VerifierAgent) å·²ç»å¤„ç†äº† Move æœºåˆ¶ç›¸å…³çš„è¯¯æŠ¥è¿‡æ»¤
    # RAG å†å²æ¼æ´æ¨¡å¼é€šè¿‡ _retrieve_similar_cases() å•ç‹¬æ£€ç´¢
    # è¿™æ ·å¯ä»¥èŠ‚çœ ~5-8K tokens/å®¡è®¡

    def retrieve_context_for_finding(self, finding: Dict) -> Dict:
        """
        ğŸ”¥ æ ¹æ® finding çš„ location è‡ªåŠ¨æ£€ç´¢ç›¸å…³ä»£ç ä¸Šä¸‹æ–‡

        Args:
            finding: æ¼æ´å‘ç°ï¼Œéœ€åŒ…å« location: {module, function}

        Returns:
            æ£€ç´¢åˆ°çš„ä»£ç ä¸Šä¸‹æ–‡
        """
        import re

        if not self.toolkit:
            return {"error": "No toolkit available", "context_summary": ""}

        location = finding.get("location", {})
        module = location.get("module", "")
        function = location.get("function", "")

        if not module or not function:
            # å°è¯•ä» title æˆ– description æå–
            title = finding.get("title", "")
            desc = finding.get("description", "")
            match = re.search(r'(\w+)::(\w+)', f"{title} {desc}")
            if match:
                module, function = match.groups()

        if not function:
            return {"error": "Cannot determine function location", "context_summary": ""}

        context_parts = []
        result = {"target_function": None, "callers": [], "callees": [], "context_summary": ""}
        caller_tag = "WhiteHat"

        # 1. è·å–ç›®æ ‡å‡½æ•°ä»£ç 
        func_result = self.toolkit.call_tool("get_function_code", {"module": module, "function": function}, caller=caller_tag)
        if func_result.success:
            result["target_function"] = func_result.data
            body = func_result.data.get("body", "")
            context_parts.append(f"## ç›®æ ‡å‡½æ•°: {module}::{function}\n```move\n{body}\n```")

        # 2. è·å–è°ƒç”¨è€…
        callers_result = self.toolkit.call_tool("get_callers", {"module": module, "function": function, "depth": 2}, caller=caller_tag)
        if callers_result.success:
            callers = callers_result.data.get("callers", [])
            result["callers"] = callers
            if callers:
                caller_names = [c.get("id", "?") for c in callers[:5]]
                context_parts.append(f"## è°ƒç”¨è€…\n" + "\n".join(f"- {n}" for n in caller_names))

        # 3. è·å–è¢«è°ƒç”¨è€…
        callees_result = self.toolkit.call_tool("get_callees", {"module": module, "function": function, "depth": 2}, caller=caller_tag)
        if callees_result.success:
            callees = callees_result.data.get("callees", [])
            result["callees"] = callees
            if callees:
                callee_names = [c.get("id", "?") for c in callees[:5]]
                context_parts.append(f"## è¢«è°ƒç”¨è€…\n" + "\n".join(f"- {n}" for n in callee_names))

        # 4. è·å–å‡½æ•°åŠŸèƒ½æè¿°
        purpose_result = self.toolkit.call_tool("get_function_purpose", {"function_id": function}, caller=caller_tag)
        if purpose_result.success:
            purpose = purpose_result.data.get("purpose", "")
            context_parts.append(f"## å‡½æ•°åŠŸèƒ½\n{purpose}")

        # 5. è·å–ç›¸å…³åˆ†ææç¤º
        hints_result = self.toolkit.call_tool("get_analysis_hints", {"hint_type": "all"}, caller=caller_tag)
        if hints_result.success:
            hints = hints_result.data
            if hints.get("analysis_summary"):
                context_parts.append(f"## åˆçº¦åˆ†ææ‘˜è¦\n{hints['analysis_summary']}")

        result["context_summary"] = "\n\n".join(context_parts)
        return result

    def _init_llm_from_config(self, config):
        """æ ¹æ® AgentConfig åˆå§‹åŒ– LLM"""
        provider_type = ProviderType(config.provider.lower())
        llm_config = LLMConfig(
            provider=provider_type,
            model=config.model,
            temperature=config.temperature,
            max_tokens=config.max_tokens,
            timeout=getattr(config, 'timeout', 120)
        )
        return LLMProviderFactory.create(llm_config)

    def verify_vulnerability(
        self,
        vulnerability: Dict,
        source_code: str = "",
        context: Optional[Dict] = None
    ) -> ExploitVerificationReport:
        """
        éªŒè¯å•ä¸ªæ¼æ´çš„çœŸå®æ€§

        ğŸ”¥ v2.5.3: åªå¤„ç† HIGH/CRITICAL ä¸¥é‡æ€§çš„æ¼æ´
        MEDIUM/LOW/ADVISORY çº§åˆ«ç›´æ¥è·³è¿‡ï¼Œå‡å°‘ token æ¶ˆè€—

        Args:
            vulnerability: æ¼æ´æ‰«æç»“æœ
            source_code: ç›¸å…³æºä»£ç ï¼ˆå¦‚æœæœ‰ toolkit åˆ™å¯é€‰ï¼‰
            context: é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆæ¨¡å—ä¿¡æ¯ã€ABI ç­‰ï¼‰

        Returns:
            ExploitVerificationReport: æ¼æ´éªŒè¯æŠ¥å‘Š
        """
        vuln_id = vulnerability.get("id", vulnerability.get("pattern_id", "UNKNOWN"))
        vuln_type = vulnerability.get("category", vulnerability.get("issue_tags", ["unknown"])[0] if vulnerability.get("issue_tags") else "unknown")
        severity = vulnerability.get("severity", "medium").lower()

        # ğŸ”¥ v2.5.3: åªå¤„ç† HIGH/CRITICAL æ¼æ´
        if severity not in ["high", "critical"]:
            print(f"â­ï¸ [WhiteHatAgent] è·³è¿‡ {vuln_id} (ä¸¥é‡æ€§: {severity}, åªå¤„ç† HIGH/CRITICAL)")
            return ExploitVerificationReport(
                vulnerability_id=vuln_id,
                vulnerability_type=vuln_type,
                severity=severity,
                status=VerificationStatus.NEEDS_REVIEW,
                confidence_score=0,
                exploitability_score=0,
                one_liner_exploit="",
                why_exploitable="",
                why_not_exploitable=f"å·²è·³è¿‡: ä¸¥é‡æ€§ä¸º {severity}ï¼ŒWhiteHat åªåˆ†æ HIGH/CRITICAL æ¼æ´",
                raw_vulnerability=vulnerability,
                analysis_reasoning=f"v2.5.3: ä¼˜åŒ– token æ¶ˆè€—ï¼Œåªå¯¹ HIGH/CRITICAL è¿›è¡Œåˆ©ç”¨é“¾åˆ†æ"
            )

        print(f"ğŸ” [WhiteHatAgent] åˆ†ææ¼æ´: {vuln_id} ({vuln_type})")

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨ toolkit æ£€ç´¢ç›¸å…³ä»£ç ï¼Œé¿å…ä¼ å…¥æ•´ä¸ªä»£ç åº“
        if self.toolkit and not source_code:
            retrieved = self.retrieve_context_for_finding(vulnerability)
            if retrieved.get("context_summary"):
                source_code = retrieved["context_summary"]
                print(f"  ğŸ“š ä½¿ç”¨å·¥å…·æ£€ç´¢äº†ç›¸å…³ä»£ç  (ç›®æ ‡å‡½æ•° + è°ƒç”¨é“¾)")
            else:
                print(f"  âš ï¸ å·¥å…·æ£€ç´¢å¤±è´¥: {retrieved.get('error', 'unknown')}")

        # Step 1: RAG æ£€ç´¢ç±»ä¼¼æ¡ˆä¾‹
        similar_cases = self._retrieve_similar_cases(vulnerability)
        rag_context = format_rag_results(similar_cases)

        # Step 2: è·å–æ¼æ´ç±»å‹å¯¹åº”çš„åˆ©ç”¨æç¤º
        exploit_hints = get_exploit_hints(vuln_type)

        # Step 3: è°ƒç”¨ LLM è¿›è¡Œå®Œæ•´çš„åˆ©ç”¨é“¾åˆ†æ
        # ğŸ”¥ å¦‚æœå¯ç”¨å·¥å…·è¾…åŠ©æ¨¡å¼ä¸”æœ‰ toolkitï¼Œä½¿ç”¨å·¥å…·è¾…åŠ©åˆ†æ
        if self.use_tools and self.toolkit:
            print(f"  ğŸ”§ ä½¿ç”¨å·¥å…·è¾…åŠ©æ¨¡å¼åˆ†ææ¼æ´...")
            analysis_result = self._analyze_with_tools(
                vulnerability=vulnerability,
                source_code=source_code,  # ğŸ”¥ ä¼ å…¥é¢„æ„å»ºçš„ä»£ç ä¸Šä¸‹æ–‡
                rag_context=rag_context,
                exploit_hints=exploit_hints,
                context=context
            )
        else:
            analysis_result = self._analyze_with_llm(
                vulnerability=vulnerability,
                source_code=source_code,
                rag_context=rag_context,
                exploit_hints=exploit_hints,
                context=context
            )

        # Step 4: è§£æ LLM å“åº”
        parsed = self._parse_analysis_result(analysis_result)

        # Step 5: ç¡®å®šéªŒè¯çŠ¶æ€
        status = self._determine_status(parsed)

        # Step 6: æ„å»ºæŠ¥å‘Š (æ”¯æŒæ–°çš„æ¼æ´éªŒè¯æ ¼å¼)

        # ä» exploit_analysis æˆ–æ—§æ ¼å¼è·å– entry_point
        exploit_analysis = parsed.get("exploit_analysis", {})
        entry_point = parsed.get("entry_point") or {
            "function": exploit_analysis.get("entry_function", ""),
            "visibility": exploit_analysis.get("entry_visibility", ""),
            "required_objects": exploit_analysis.get("required_objects", []),
            "required_capabilities": exploit_analysis.get("required_capabilities", ""),
            "attack_type": exploit_analysis.get("attack_type", "")
        } if exploit_analysis else None

        # ä» exploit_attempt è·å–å¤±è´¥åŸå› ï¼ˆå¦‚æœä¸å¯åˆ©ç”¨ï¼‰
        exploit_attempt = parsed.get("exploit_attempt", {})
        why_not = parsed.get("why_not_exploitable") or parsed.get("reason")
        if not why_not and exploit_attempt:
            why_not = f"å°è¯•äº† {exploit_attempt.get('what_i_tried', '?')}ï¼Œåœ¨ {exploit_attempt.get('where_it_failed', '?')} å¤±è´¥"

        return ExploitVerificationReport(
            vulnerability_id=vuln_id,
            vulnerability_type=vuln_type,
            severity=severity,
            status=status,
            confidence_score=parsed.get("confidence", 50),
            exploitability_score=parsed.get("exploitability_score", 5.0),

            # å®‰å…¨å…¬å‘Šæ ¼å¼å­—æ®µ
            advisory=parsed.get("advisory", {}),
            vulnerability_summary=parsed.get("vulnerability_summary", ""),
            technical_details=parsed.get("technical_details", {}),
            attack_scenario=parsed.get("attack_scenario", []),
            poc_code=parsed.get("poc_code", ""),
            impact_assessment=parsed.get("impact_assessment", {}),
            recommended_mitigation=parsed.get("recommended_mitigation", []),
            blocking_factors=parsed.get("blocking_factors", []),

            # åˆ©ç”¨é“¾åˆ†æ
            entry_point=entry_point,
            attack_path=parsed.get("attack_path", []),
            preconditions=parsed.get("preconditions", []),
            impact=parsed.get("impact") or parsed.get("impact_assessment"),

            # ç»“è®º
            one_liner_exploit=parsed.get("vulnerability_summary", "")[:200] if parsed.get("vulnerability_summary") else "",
            why_exploitable=parsed.get("vulnerability_summary", ""),
            why_not_exploitable=why_not,

            # ğŸ”¥ å®Œæ•´çš„ exploit ä»£ç å’Œæ€è·¯
            exploit_module_code=self._format_exploit_code(parsed.get("poc_code", "")),
            exploit_reasoning=parsed.get("exploit_reasoning", ""),

            # å‚è€ƒ
            similar_cases=[c.get("title", c.get("id", "")) for c in similar_cases[:5]],
            rag_sources=[c.get("id", "") for c in similar_cases[:5]],
            raw_vulnerability=vulnerability,
            analysis_reasoning=parsed.get("reasoning", analysis_result)
        )

    def verify_all(
        self,
        vulnerabilities: List[Dict],
        source_code: str,
        context: Optional[Dict] = None
    ) -> Dict[str, List[ExploitVerificationReport]]:
        """
        æ‰¹é‡éªŒè¯æ¼æ´

        Args:
            vulnerabilities: æ¼æ´åˆ—è¡¨
            source_code: æºä»£ç 
            context: ä¸Šä¸‹æ–‡

        Returns:
            æŒ‰çŠ¶æ€åˆ†ç»„çš„éªŒè¯æŠ¥å‘Š
        """
        results = {
            "verified": [],      # å·²éªŒè¯å¯åˆ©ç”¨
            "likely": [],        # å¾ˆå¯èƒ½å¯åˆ©ç”¨
            "needs_review": [],  # éœ€è¦å®¡æŸ¥
            "theoretical": [],   # ç†è®ºæ€§
            "false_positive": [] # è¯¯æŠ¥
        }

        print(f"ğŸ© [WhiteHatAgent] å¼€å§‹éªŒè¯ {len(vulnerabilities)} ä¸ªæ¼æ´...")

        for i, vuln in enumerate(vulnerabilities, 1):
            vuln_id = vuln.get("id", vuln.get("pattern_id", f"VULN-{i}"))
            print(f"\n[{i}/{len(vulnerabilities)}] éªŒè¯: {vuln_id}")

            report = self.verify_vulnerability(vuln, source_code, context)

            # æŒ‰çŠ¶æ€åˆ†ç±»
            status_key = report.status.value
            if status_key in results:
                results[status_key].append(report)
            else:
                results["needs_review"].append(report)

            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            status_emoji = {
                VerificationStatus.VERIFIED: "ğŸ”´ å·²éªŒè¯",
                VerificationStatus.LIKELY: "ğŸŸ  å¾ˆå¯èƒ½",
                VerificationStatus.NEEDS_REVIEW: "ğŸŸ¡ éœ€å®¡æŸ¥",
                VerificationStatus.THEORETICAL: "âšª ç†è®ºæ€§",
                VerificationStatus.FALSE_POSITIVE: "ğŸŸ¢ è¯¯æŠ¥",
            }
            print(f"   â†’ {status_emoji.get(report.status, 'â“')} | å¯åˆ©ç”¨æ€§: {report.exploitability_score}/10")

        # æ‰“å°ç»Ÿè®¡
        print(f"\n{'='*50}")
        print("ğŸ“Š éªŒè¯ç»Ÿè®¡:")
        print(f"   ğŸ”´ å·²éªŒè¯æ¼æ´: {len(results['verified'])}")
        print(f"   ğŸŸ  å¾ˆå¯èƒ½æ¼æ´: {len(results['likely'])}")
        print(f"   ğŸŸ¡ éœ€è¦å®¡æŸ¥: {len(results['needs_review'])}")
        print(f"   âšª ç†è®ºæ€§æ¼æ´: {len(results['theoretical'])}")
        print(f"   ğŸŸ¢ è¯¯æŠ¥: {len(results['false_positive'])}")
        print(f"{'='*50}")

        return results

    def _retrieve_similar_cases(self, vulnerability: Dict) -> List[Dict]:
        """ä» RAG æ£€ç´¢ç±»ä¼¼çš„å†å²æ¼æ´æ¡ˆä¾‹"""
        if not self.rag_retriever:
            return []

        try:
            query = build_rag_query(vulnerability)
            results = self.rag_retriever.search(query=query, top_k=10)
            return results
        except Exception as e:
            print(f"   âš ï¸ RAG æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _analyze_with_llm(
        self,
        vulnerability: Dict,
        source_code: str,
        rag_context: str,
        exploit_hints: Dict,
        context: Optional[Dict]
    ) -> str:
        """ä½¿ç”¨ LLM è¿›è¡Œåˆ©ç”¨é“¾åˆ†æ"""

        # å‡†å¤‡æ¼æ´ä¿¡æ¯
        vuln_id = vulnerability.get("id", vulnerability.get("pattern_id", "UNKNOWN"))
        vuln_type = vulnerability.get("category", "unknown")
        severity = vulnerability.get("severity", "medium")
        location = vulnerability.get("location", {})
        description = vulnerability.get("description", vulnerability.get("recommendation", ""))

        # æ„å»ºä½ç½®å­—ç¬¦ä¸²
        location_str = ""
        if isinstance(location, dict):
            location_str = f"{location.get('module', 'unknown')}::{location.get('function', 'unknown')}"
        elif isinstance(location, str):
            location_str = location
        else:
            location_str = str(location)

        # ğŸ”¥ v2.5.7: ç§»é™¤å®‰å…¨çŸ¥è¯†æ³¨å…¥ï¼ŒPhase 3 å·²å¤„ç†æœºåˆ¶è¿‡æ»¤
        # RAG å†å²æ¼æ´æ¡ˆä¾‹é€šè¿‡ rag_context å‚æ•°ä¼ å…¥

        # æ„å»ºåˆ†ææç¤ºè¯ (æ¼æ´ä¿¡æ¯ + ä»£ç  + ç»Ÿä¸€çš„éªŒè¯æŒ‡å—)
        prompt = f"""
## å‰é¢Agentå‘ç°çš„æ½œåœ¨æ¼æ´

**ID**: {vuln_id}
**ç±»å‹**: {vuln_type}
**ä¸¥é‡æ€§**: {severity}
**ä½ç½®**: {location_str}
**æè¿°**: {description}

## ç›®æ ‡åˆçº¦æºä»£ç 

```move
{source_code[:6000]}
```

## ç±»ä¼¼æ¼æ´çš„å†å²æ¡ˆä¾‹

{rag_context}

{WHITE_HAT_VERIFICATION_PROMPT}
"""

        # æ·»åŠ åˆ©ç”¨æç¤º
        if exploit_hints:
            prompt += f"""

## è¯¥æ¼æ´ç±»å‹çš„å¸¸è§åˆ©ç”¨æ¨¡å¼

- **å…¸å‹å…¥å£**: {exploit_hints.get('typical_entry', 'unknown')}
- **æ”»å‡»æ–¹å¼**: {exploit_hints.get('attack_hint', '')}
- **å‰ç½®æ¡ä»¶**: {exploit_hints.get('precondition_hint', '')}
- **é¢„æœŸå½±å“**: {exploit_hints.get('impact_hint', '')}
"""

        # å¸¦é‡è¯•çš„ LLM è°ƒç”¨ (å¤„ç† 429 rate limit)
        # ğŸ”¥ å¢å¼ºé‡è¯•: æ›´å¤šæ¬¡æ•° + æ›´é•¿é€€é¿ + éšæœºæŠ–åŠ¨
        import random
        max_retries = 5  # è‡³å°‘5æ¬¡é‡è¯•
        base_delay = 3.0  # åŸºç¡€å»¶è¿Ÿ3ç§’
        max_delay = 30.0  # æœ€å¤§å»¶è¿Ÿ30ç§’

        for attempt in range(max_retries):
            try:
                # ğŸ”¥ ä½¿ç”¨é”åºåˆ—åŒ–åŒä¸€å®ä¾‹çš„ LLM è°ƒç”¨ï¼Œé¿å…å¹¶å‘è¸©è¸
                with self._llm_lock:
                    # å‚ç…§ BaseAgent.call_llm() å®ç°
                    # åˆ¤æ–­æ˜¯ä½¿ç”¨ Provider (.chat) è¿˜æ˜¯ LangChain (.invoke)
                    if hasattr(self.llm, 'chat'):
                        # ä½¿ç”¨ LLMProvider (æ–°ç³»ç»Ÿ)
                        messages = [
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç™½å¸½é»‘å®¢ï¼Œæ“…é•¿åˆ†ææ™ºèƒ½åˆçº¦æ¼æ´çš„å¯åˆ©ç”¨æ€§ã€‚"},
                            {"role": "user", "content": prompt}
                        ]
                        response = self.llm.chat(messages)
                        # ğŸ”¥ v2.5.8: è¿½è¸ª token ä½¿ç”¨é‡
                        if hasattr(response, 'usage') and response.usage:
                            self._track_token_usage(response.usage)
                        content = response.content
                    else:
                        # ä½¿ç”¨ LangChain (ä¼ ç»Ÿæ–¹å¼)
                        response = self.llm.invoke(prompt)
                        content = response.content if hasattr(response, 'content') else str(response)
                return content
            except Exception as e:
                error_str = str(e)
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 rate limit é”™è¯¯
                if "429" in error_str or "rate" in error_str.lower() or "1302" in error_str:
                    if attempt < max_retries - 1:
                        # ğŸ”¥ æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨ (é¿å…å¤šAgentåŒæ—¶é‡è¯•)
                        delay = min(base_delay * (2 ** attempt), max_delay)
                        jitter = random.uniform(0.5, 1.5)  # 0.5x ~ 1.5x éšæœºå› å­
                        actual_delay = delay * jitter
                        print(f"   â³ API é™æµï¼Œ{actual_delay:.1f}s åé‡è¯• ({attempt + 1}/{max_retries})...")
                        time.sleep(actual_delay)
                        continue

                print(f"   âš ï¸ LLM åˆ†æå¤±è´¥: {e}")
                return json.dumps({
                    "is_exploitable": False,
                    "confidence": "low",
                    "exploitability_score": 2,
                    "reason": f"LLM åˆ†æå¤±è´¥: {str(e)[:100]}"
                })

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return json.dumps({
            "is_exploitable": False,
            "confidence": "low",
            "exploitability_score": 2,
            "reason": "API é™æµï¼Œæ‰€æœ‰é‡è¯•å‡å¤±è´¥"
        })

    def _run_lightweight_verification(
        self,
        vuln_id: str,
        minimal_prompt: str,
        tools: list,
        max_rounds: int = 5
    ) -> str:
        """
        ğŸ”¥ è½»é‡çº§å­ Agentï¼šç‹¬ç«‹ä¼šè¯ + ç‹¬ç«‹ LLM å®ä¾‹

        æ ¸å¿ƒä¼˜åŒ– (v2.4.8):
        1. æ¯æ¬¡éªŒè¯ä½¿ç”¨å…¨æ–°çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œä¸å¸¦ä¸» Agent çš„å†å²ä¸Šä¸‹æ–‡
        2. åˆ›å»ºç‹¬ç«‹çš„ LLM å®ä¾‹ï¼Œä¸å…±äº«ä¸» Agent çš„é” â†’ æ”¯æŒå¹¶è¡Œæ‰§è¡Œ
        3. åªä¼ é€’å¿…è¦ä¿¡æ¯ï¼šæ¼æ´æè¿° + é¢„æ„å»ºä»£ç  + å‡½æ•°ç´¢å¼•
        4. å·¥å…·è°ƒç”¨åœ¨éš”ç¦»ç¯å¢ƒä¸­å®Œæˆï¼Œç»“æœè¿”å›ç»™ä¸»æµç¨‹

        è¿™ç›¸å½“äº "çœŸæ­£çš„å­ Agent"ï¼š
        - ä¸» Agent: ä¿æŒå®Œæ•´ä¸Šä¸‹æ–‡ï¼Œè´Ÿè´£åè°ƒ
        - å­ Agent: ç‹¬ç«‹ LLM + æœ€å°ä¸Šä¸‹æ–‡ï¼Œä¸“æ³¨äºå•ä¸ªæ¼æ´éªŒè¯

        Args:
            vuln_id: æ¼æ´ IDï¼ˆç”¨äºæ—¥å¿—ï¼‰
            minimal_prompt: ç²¾ç®€çš„éªŒè¯ promptï¼ˆåªå«å¿…è¦ä¿¡æ¯ï¼‰
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            max_rounds: æœ€å¤§å·¥å…·è°ƒç”¨è½®æ¬¡

        Returns:
            LLM çš„æœ€ç»ˆåˆ†æç»“æœï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
        """
        import random
        import time

        # ğŸ”¥ v2.4.8: åˆ›å»ºç‹¬ç«‹çš„ LLM å®ä¾‹ï¼Œä¸å…±äº«ä¸» Agent çš„é”
        # è¿™æ˜¯å®ç°çœŸæ­£å¹¶è¡Œæ‰§è¡Œçš„å…³é”®
        sub_agent_llm = self._init_llm_from_config(self.config)

        # ğŸ”¥ è½»é‡çº§ç³»ç»Ÿ promptï¼ˆæ¯”ä¸» Agent çŸ­å¾—å¤šï¼‰
        system_prompt = """ä½ æ˜¯ç™½å¸½å®‰å…¨éªŒè¯å­ç¨‹åºï¼Œä¸“æ³¨äºéªŒè¯å•ä¸ªæ¼æ´ã€‚

å·¥ä½œåŸåˆ™ï¼š
1. ç›´æ¥åˆ†ææä¾›çš„ä»£ç ï¼Œé«˜æ•ˆä½¿ç”¨å·¥å…·
2. æ¯è½®æœ€å¤šè°ƒç”¨ 2 ä¸ªå·¥å…·
3. æ”¶é›†è¶³å¤Ÿä¿¡æ¯åç«‹å³è¾“å‡º JSON ç»“æœ
4. ä¸è¦é‡å¤è·å–ç›¸åŒä¿¡æ¯
5. **æ‰€æœ‰è¾“å‡ºå¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼**

è¾“å‡ºæ ¼å¼ï¼ˆæ‰€æœ‰å­—æ®µå¿…é¡»ç”¨ä¸­æ–‡ï¼‰ï¼š
{
  "is_exploitable": true/false,
  "exploitability_score": 0-10,
  "confidence": "low/medium/high",
  "exploit_summary": "ä¸€å¥è¯åˆ©ç”¨æ–¹æ³•ï¼ˆä¸­æ–‡ï¼‰",
  "attack_steps": ["æ­¥éª¤1ï¼ˆä¸­æ–‡ï¼‰", "æ­¥éª¤2ï¼ˆä¸­æ–‡ï¼‰"],
  "poc_code": "exploit ä»£ç ",
  "blocking_factors": ["é˜»æ–­å› ç´ ï¼ˆä¸­æ–‡ï¼Œå¦‚æœä¸å¯åˆ©ç”¨ï¼‰"]
}"""

        # ğŸ”¥ åˆ›å»ºå…¨æ–°çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¸å¸¦ä»»ä½•å†å²ä¸Šä¸‹æ–‡ï¼‰
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": minimal_prompt}
        ]

        # å·¥å…·è°ƒç”¨å»é‡
        called_tools: set = set()

        def get_tool_key(name: str, args: dict) -> str:
            import json as _json
            return f"{name}:{_json.dumps(args, sort_keys=True, ensure_ascii=False)}"

        # ğŸ”¥ è½»é‡çº§å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆä½¿ç”¨ç‹¬ç«‹ LLMï¼Œæ— é”ï¼‰
        for round_num in range(max_rounds):
            try:
                # ğŸ”¥ ä¸éœ€è¦é”ï¼Œå› ä¸ºæ˜¯ç‹¬ç«‹çš„ LLM å®ä¾‹
                response = sub_agent_llm.chat(messages, tools=tools)
                # ğŸ”¥ v2.5.8: è¿½è¸ªå­ Agent token ä½¿ç”¨é‡
                if hasattr(response, 'usage') and response.usage:
                    self._track_token_usage(response.usage)
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "rate" in error_str.lower():
                    delay = 2.0 * (2 ** round_num) * random.uniform(0.5, 1.5)
                    print(f"      â³ [{vuln_id}] API é™æµï¼Œ{delay:.1f}s åé‡è¯•...")
                    time.sleep(delay)
                    continue
                return json.dumps({
                    "is_exploitable": False,
                    "confidence": "low",
                    "reason": f"å­ Agent è°ƒç”¨å¤±è´¥: {str(e)[:100]}"
                })

            # æ£€æŸ¥æ˜¯å¦å®Œæˆï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰
            if response.finish_reason != "tool_calls" or not response.tool_calls:
                if round_num > 0:
                    print(f"      âœ“ [{vuln_id}] å­ Agent å®Œæˆ (å…± {round_num + 1} è½®, {len(called_tools)} æ¬¡å·¥å…·è°ƒç”¨)")
                return response.content or ""

            # è¿‡æ»¤é‡å¤å·¥å…·è°ƒç”¨
            unique_calls = []
            for tc in response.tool_calls:
                tool_key = get_tool_key(tc.name, tc.arguments)
                if tool_key not in called_tools:
                    called_tools.add(tool_key)
                    unique_calls.append(tc)

            if not unique_calls:
                # æ‰€æœ‰è°ƒç”¨éƒ½é‡å¤ï¼Œå¼ºåˆ¶è¾“å‡º
                messages.append({
                    "role": "user",
                    "content": "æ‰€æœ‰è¯·æ±‚çš„å·¥å…·å·²æ‰§è¡Œè¿‡ã€‚è¯·ç«‹å³è¾“å‡º JSON åˆ†æç»“æœã€‚"
                })
                try:
                    final_resp = sub_agent_llm.chat(messages)
                    # ğŸ”¥ v2.5.8: è¿½è¸ªå­ Agent token ä½¿ç”¨é‡
                    if hasattr(final_resp, 'usage') and final_resp.usage:
                        self._track_token_usage(final_resp.usage)
                    return final_resp.content or ""
                except:
                    break

            # è®°å½•å·¥å…·è°ƒç”¨
            messages.append({
                "role": "assistant",
                "content": response.content or "",
                "tool_calls": [{"id": tc.id, "name": tc.name, "args": tc.arguments} for tc in unique_calls]
            })

            # æ‰§è¡Œå·¥å…·
            for tc in unique_calls:
                args_summary = tc.arguments.get("function", tc.arguments.get("type_name", "?"))
                result = self.toolkit.call_tool(tc.name, tc.arguments, caller=f"SubAgent-{vuln_id}")
                tool_output = json.dumps(result.data, ensure_ascii=False)[:2000] if result.success else f"Error: {result.error}"
                messages.append({"role": "tool", "tool_call_id": tc.id, "content": tool_output})
                print(f"      ğŸ”§ [{vuln_id}] {tc.name}({args_summary})")

        # æœ€å¤§è½®æ¬¡è€—å°½
        messages.append({"role": "user", "content": "è¯·ç«‹å³è¾“å‡º JSON åˆ†æç»“æœï¼Œä¸å†è°ƒç”¨å·¥å…·ã€‚"})
        try:
            final_resp = sub_agent_llm.chat(messages)
            # ğŸ”¥ v2.5.8: è¿½è¸ªå­ Agent token ä½¿ç”¨é‡
            if hasattr(final_resp, 'usage') and final_resp.usage:
                self._track_token_usage(final_resp.usage)
            return final_resp.content or ""
        except:
            return json.dumps({"is_exploitable": False, "confidence": "low", "reason": "å­ Agent è½®æ¬¡è€—å°½"})

    def _analyze_with_tools(
        self,
        vulnerability: Dict,
        source_code: str,  # ğŸ”¥ æ·»åŠ ï¼šé¢„æ„å»ºçš„ä»£ç ä¸Šä¸‹æ–‡
        rag_context: str,
        exploit_hints: Dict,
        context: Optional[Dict]
    ) -> str:
        """
        ğŸ”¥ ä½¿ç”¨å·¥å…·è¾…åŠ©åˆ†ææ¼æ´ (å­ Agent å§”æ‰˜æ¨¡å¼)

        æ ¸å¿ƒæ”¹è¿› (v2.4.7):
        1. é¢„æ„å»ºçš„ä»£ç ä¸Šä¸‹æ–‡ç›´æ¥ç»™ LLM
        2. å§”æ‰˜ç»™è½»é‡çº§å­ Agent æ‰§è¡Œå·¥å…·è°ƒç”¨
        3. å­ Agent ä½¿ç”¨æœ€å°ä¸Šä¸‹æ–‡ï¼Œé¿å…ä¸Šä¸‹æ–‡è†¨èƒ€
        """
        if not self.toolkit:
            print("   âš ï¸ å·¥å…·è¾…åŠ©æ¨¡å¼éœ€è¦ toolkitï¼Œå›é€€åˆ°æ™®é€šåˆ†æ")
            return self._analyze_with_llm(vulnerability, source_code, rag_context, exploit_hints, context)

        # è·å–å‡½æ•°ç´¢å¼•å’Œåˆ†æä¸Šä¸‹æ–‡
        function_index = self.toolkit.get_function_index()
        analysis_context = self.toolkit.get_analysis_context()

        # å‡†å¤‡æ¼æ´ä¿¡æ¯
        vuln_id = vulnerability.get("id", vulnerability.get("pattern_id", "UNKNOWN"))
        vuln_type = vulnerability.get("category", "unknown")
        severity = vulnerability.get("severity", "medium")
        location = vulnerability.get("location", {})
        description = vulnerability.get("description", vulnerability.get("recommendation", ""))

        # æ„å»ºä½ç½®å­—ç¬¦ä¸²
        location_str = ""
        if isinstance(location, dict):
            location_str = f"{location.get('module', 'unknown')}::{location.get('function', 'unknown')}"
        elif isinstance(location, str):
            location_str = location
        else:
            location_str = str(location)

        # ğŸ”¥ åˆ¤æ–­æ˜¯å¦æœ‰é¢„æ„å»ºçš„ä»£ç ä¸Šä¸‹æ–‡
        has_prebuilt_context = bool(source_code and len(source_code.strip()) > 100)

        # æ˜¾ç¤ºé¢„æ„å»ºä¸Šä¸‹æ–‡çŠ¶æ€
        if has_prebuilt_context:
            # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ¥è‡ª Phase 3
            context_type = context.get("context_type", "") if context else ""
            if context_type == "phase3_inherited":
                print(f"       â†’ Phase 3 ä¸Šä¸‹æ–‡: {len(source_code)} å­—ç¬¦ (ç»§æ‰¿)")
            else:
                print(f"       â†’ é¢„æ„å»ºä¸Šä¸‹æ–‡: {len(source_code)} å­—ç¬¦")
        else:
            print(f"       â†’ æ— é¢„æ„å»ºä¸Šä¸‹æ–‡ï¼Œå°†ä½¿ç”¨å·¥å…·è·å–ä»£ç ")

        # ğŸ”¥ æ˜¾ç¤º Phase 3 åˆ†æç»“æœçŠ¶æ€
        phase3_ctx = context.get("phase3_analysis", {}) if context else {}
        if phase3_ctx:
            p3_status = phase3_ctx.get("verification_status", "")
            p3_conf = phase3_ctx.get("final_confidence", 0)
            print(f"       â†’ Phase 3 éªŒè¯: {p3_status} ({p3_conf}% ç½®ä¿¡åº¦)")

        # ğŸ”¥ æå– Phase 3 åˆ†æç»“æœ
        phase3_analysis = context.get("phase3_analysis", {}) if context else {}
        phase3_section = ""
        if phase3_analysis:
            expert_review = phase3_analysis.get("expert_review", {})
            analyst_assessment = phase3_analysis.get("analyst_assessment", {})
            verification_reasoning = phase3_analysis.get("verification_reasoning", [])

            # æ„å»º Phase 3 åˆ†ææ‘˜è¦
            phase3_lines = ["## ğŸ“‹ Phase 3 å¤šAgentéªŒè¯ç»“æœ (å·²å®Œæˆ)"]
            phase3_lines.append(f"- éªŒè¯çŠ¶æ€: {phase3_analysis.get('verification_status', 'unknown')}")
            phase3_lines.append(f"- ç½®ä¿¡åº¦: {phase3_analysis.get('final_confidence', 0)}%")

            # Expert åˆ†æ
            if expert_review:
                expert_status = expert_review.get("verification", {}).get("status", "")
                expert_reasoning = expert_review.get("verification", {}).get("reasoning", "")[:300]
                if expert_status:
                    phase3_lines.append(f"\n### Expert æŠ€æœ¯åˆ†æ:")
                    phase3_lines.append(f"- ç»“è®º: {expert_status}")
                    if expert_reasoning:
                        phase3_lines.append(f"- æ¨ç†: {expert_reasoning}")

            # Analyst åˆ†æ
            if analyst_assessment:
                priority = analyst_assessment.get("mitigation_priority", "")
                attack_scenario = analyst_assessment.get("attack_scenario", "")[:300]
                if priority:
                    phase3_lines.append(f"\n### Analyst ä¸šåŠ¡å½±å“:")
                    phase3_lines.append(f"- ä¼˜å…ˆçº§: {priority}")
                    if attack_scenario:
                        phase3_lines.append(f"- æ”»å‡»åœºæ™¯: {attack_scenario}")

            # å„è½®æ¬¡æ¨ç†
            if verification_reasoning:
                phase3_lines.append(f"\n### éªŒè¯è½®æ¬¡æ‘˜è¦:")
                for r in verification_reasoning:
                    phase3_lines.append(f"- [{r['agent']}] {r['verdict']} ({r['confidence']}%)")

            phase3_section = "\n".join(phase3_lines)

        # ğŸ”¥ v2.5.7: ç§»é™¤å®‰å…¨çŸ¥è¯†æ³¨å…¥ï¼ŒPhase 3 å·²å¤„ç†æœºåˆ¶è¿‡æ»¤
        # RAG å†å²æ¼æ´æ¡ˆä¾‹é€šè¿‡ rag_context å‚æ•°ä¼ å…¥

        # æ„å»ºå·¥å…·è¾…åŠ©åˆ†æ prompt
        prompt = f"""
## æ¼æ´ä¿¡æ¯
- ID: {vuln_id}
- ç±»å‹: {vuln_type}
- ä¸¥é‡æ€§: {severity}
- ä½ç½®: {location_str}
- æè¿°: {description}

{phase3_section}

## ğŸ”¥ é¢„æ„å»ºçš„ä»£ç ä¸Šä¸‹æ–‡ (æ¥è‡ªPhase 3åˆ†æ)
{"```move" + chr(10) + source_code[:8000] + chr(10) + "```" if has_prebuilt_context else "æ— é¢„æ„å»ºä¸Šä¸‹æ–‡"}

## ğŸ“ å·¥å…·ä½¿ç”¨æŒ‡å—
{"ä¸Šé¢å·²ç»æä¾›äº†æ¼æ´å‡½æ•°åŠå…¶è°ƒç”¨é“¾çš„ä»£ç ï¼ˆä¸Phase 3ç›¸åŒï¼‰ã€‚è¯·ä¼˜å…ˆåŸºäºè¿™äº›ä»£ç è¿›è¡Œåˆ©ç”¨é“¾åˆ†æã€‚" if has_prebuilt_context else "è¯·ä½¿ç”¨å·¥å…·è·å–ä»£ç è¿›è¡Œåˆ†æã€‚"}
- **åªæœ‰åœ¨ä»¥ä¸‹æƒ…å†µæ‰éœ€è¦è°ƒç”¨å·¥å…·**ï¼š
  1. éœ€è¦æŸ¥çœ‹è·¨æ¨¡å—çš„å‡½æ•°å®ç°
  2. éœ€è¦è·å–ç±»å‹å®šä¹‰ (struct abilities)
  3. éœ€è¦è¿½è¸ªæ›´æ·±çš„è°ƒç”¨é“¾
- **æ•ˆç‡è¦æ±‚**ï¼šæ¯è½®æœ€å¤šè°ƒç”¨ 2 ä¸ªå·¥å…·ï¼Œé¿å…é‡å¤è°ƒç”¨
- **é‡ç‚¹**ï¼šPhase 3 å·²ç¡®è®¤æ¼æ´å­˜åœ¨ï¼Œä½ çš„ä»»åŠ¡æ˜¯åˆ†æå¦‚ä½•åˆ©ç”¨å®ƒ

## å¯ç”¨å‡½æ•°ç´¢å¼• (ç”¨äºå·¥å…·è°ƒç”¨)
{function_index}

## ç±»ä¼¼æ¼æ´æ¡ˆä¾‹ (RAG)
{rag_context}

{WHITE_HAT_VERIFICATION_PROMPT}
"""

        # æ·»åŠ åˆ©ç”¨æç¤º
        if exploit_hints:
            prompt += f"""
## è¯¥æ¼æ´ç±»å‹çš„å¸¸è§åˆ©ç”¨æ¨¡å¼
- **å…¸å‹å…¥å£**: {exploit_hints.get('typical_entry', 'unknown')}
- **æ”»å‡»æ–¹å¼**: {exploit_hints.get('attack_hint', '')}
- **å‰ç½®æ¡ä»¶**: {exploit_hints.get('precondition_hint', '')}
- **é¢„æœŸå½±å“**: {exploit_hints.get('impact_hint', '')}
"""

        # è·å–å®‰å…¨å·¥å…·
        tools = self.toolkit.get_security_tools()

        # ============================================================
        # ğŸ”¥ v2.4.7: å­ Agent å§”æ‰˜æ¨¡å¼
        # å°†å·¥å…·è°ƒç”¨å¾ªç¯å§”æ‰˜ç»™è½»é‡çº§å­ Agentï¼Œé¿å…ä¸Šä¸‹æ–‡è†¨èƒ€
        # ============================================================

        # ğŸ”¥ æ„å»ºç²¾ç®€çš„å­ Agent promptï¼ˆåªå«å¿…è¦ä¿¡æ¯ï¼‰
        minimal_prompt = f"""## æ¼æ´éªŒè¯ä»»åŠ¡

**æ¼æ´ä¿¡æ¯**:
- ID: {vuln_id}
- ç±»å‹: {vuln_type}
- ä¸¥é‡æ€§: {severity}
- ä½ç½®: {location_str}
- æè¿°: {description[:500]}

**Phase 3 åˆ†æç»“è®º**: {phase3_ctx.get('verification_status', 'unknown')} ({phase3_ctx.get('final_confidence', 0)}% ç½®ä¿¡åº¦)

**ä»£ç ä¸Šä¸‹æ–‡**:
```move
{source_code[:6000] if has_prebuilt_context else "è¯·ä½¿ç”¨å·¥å…·è·å–ä»£ç "}
```

**å¯ç”¨å‡½æ•°**: {function_index[:1500]}

**ä»»åŠ¡**: éªŒè¯æ­¤æ¼æ´æ˜¯å¦å¯è¢«åˆ©ç”¨ï¼Œæ„å»ºå®Œæ•´çš„ exploitã€‚å¦‚æœä»£ç å·²è¶³å¤Ÿåˆ†æï¼Œç›´æ¥è¾“å‡ºç»“è®ºï¼›å¦‚éœ€æ›´å¤šä»£ç ï¼Œä½¿ç”¨å·¥å…·è·å–ã€‚"""

        # æ·»åŠ  RAG ä¸Šä¸‹æ–‡ï¼ˆç²¾ç®€ç‰ˆï¼‰
        if rag_context and len(rag_context) > 50:
            minimal_prompt += f"\n\n**ç±»ä¼¼æ¼æ´æ¡ˆä¾‹**: {rag_context[:800]}"

        # æ·»åŠ åˆ©ç”¨æç¤º
        if exploit_hints:
            minimal_prompt += f"""

**åˆ©ç”¨æç¤º**:
- å…¥å£: {exploit_hints.get('typical_entry', 'unknown')}
- æ”»å‡»æ–¹å¼: {exploit_hints.get('attack_hint', '')[:200]}"""

        print(f"   ğŸš€ [{vuln_id}] å§”æ‰˜ç»™å­ Agent (ä¸Šä¸‹æ–‡: {len(minimal_prompt)} å­—ç¬¦)")

        # ğŸ”¥ å§”æ‰˜ç»™è½»é‡çº§å­ Agent æ‰§è¡Œ
        result = self._run_lightweight_verification(
            vuln_id=vuln_id,
            minimal_prompt=minimal_prompt,
            tools=tools,
            max_rounds=5
        )

        # å¦‚æœå­ Agent æˆåŠŸè¿”å›ç»“æœï¼Œç›´æ¥ä½¿ç”¨
        if result and len(result.strip()) > 10:
            return result

        # å­ Agent å¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥åˆ†æ
        print(f"   âš ï¸ [{vuln_id}] å­ Agent æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œå›é€€åˆ°ç›´æ¥åˆ†æ")
        return self._analyze_with_llm(vulnerability, source_code, rag_context, exploit_hints, context)

    # æ³¨: æ—§ç‰ˆ _analyze_with_tools_legacy å·²ç§»é™¤ (v2.4.7)
    # å¦‚éœ€å‚è€ƒæ—§å®ç°ï¼Œè¯·æŸ¥çœ‹ git å†å²è®°å½•

    def _parse_analysis_result(self, result: str) -> Dict:
        """è§£æ LLM åˆ†æç»“æœ - ä½¿ç”¨ json_parser å·¥å…·æ¨¡å—çš„ 9 ç§ç­–ç•¥"""
        # ğŸ”¥ ä½¿ç”¨å·¥å…·æ¨¡å—çš„å¥å£® JSON è§£æå™¨
        parsed = robust_parse_json(result, verbose=True)

        # æ£€æŸ¥æ˜¯å¦è§£ææˆåŠŸ
        if "error" not in parsed:
            return parsed

        # 9 ç§ç­–ç•¥éƒ½å¤±è´¥äº†ï¼Œå°è¯• WhiteHat ä¸“ç”¨çš„å­—æ®µæå–
        print(f"   âš ï¸ 9 ç§ç­–ç•¥å¤±è´¥ï¼Œå°è¯• WhiteHat å­—æ®µæå–...")
        extracted = extract_fields_regex(result, WHITEHAT_FIELD_PATTERNS)

        if extracted.get("is_exploitable") is not None:
            return {
                "is_exploitable": extracted.get("is_exploitable", False),
                "confidence": extracted.get("confidence", "medium"),
                "exploitability_score": extracted.get("exploitability_score", 5),
                "exploit_reasoning": extracted.get("exploit_reasoning", ""),
                "reason": "WhiteHat å­—æ®µæå–æˆåŠŸ",
                "_partial_parse": True
            }

        print(f"   âš ï¸ æ‰€æœ‰è§£æç­–ç•¥å¤±è´¥ï¼ŒåŸå§‹å“åº”å‰200å­—ç¬¦: {result[:200]}...")
        return {
            "is_exploitable": False,
            "confidence": "low",
            "exploitability_score": 3,
            "reason": "æ— æ³•è§£æ LLM å“åº”",
            "reasoning": result[:500]
        }

    def _format_exploit_code(self, code: str) -> str:
        """æ ¼å¼åŒ– exploit ä»£ç ï¼Œå¤„ç†è½¬ä¹‰å­—ç¬¦"""
        if not code:
            return ""
        # å¤„ç† JSON ä¸­çš„è½¬ä¹‰æ¢è¡Œç¬¦
        formatted = code.replace("\\n", "\n").replace("\\t", "    ")
        # ç§»é™¤å¤šä½™çš„è½¬ä¹‰
        formatted = formatted.replace('\\"', '"')
        return formatted.strip()

    def _determine_status(self, parsed: Dict) -> VerificationStatus:
        """æ ¹æ®åˆ†æç»“æœç¡®å®šéªŒè¯çŠ¶æ€"""
        is_exploitable = parsed.get("is_exploitable", False)
        confidence = parsed.get("confidence", "low")
        score = parsed.get("exploitability_score", 5)

        # æ˜ å°„ç½®ä¿¡åº¦å­—ç¬¦ä¸²åˆ°æ•°å€¼
        confidence_map = {
            "high": 85,
            "medium": 60,
            "low": 35,
            "theoretical": 15
        }

        if isinstance(confidence, str):
            confidence_num = confidence_map.get(confidence.lower(), 50)
        else:
            confidence_num = confidence

        # æ›´æ–° parsed ä¸­çš„ç½®ä¿¡åº¦æ•°å€¼
        parsed["confidence"] = confidence_num

        # æ ¹æ®ç»„åˆæ¡ä»¶åˆ¤æ–­çŠ¶æ€
        if is_exploitable and confidence_num >= 80 and score >= 7:
            return VerificationStatus.VERIFIED
        elif is_exploitable and confidence_num >= 60 and score >= 5:
            return VerificationStatus.LIKELY
        elif is_exploitable and score >= 4:
            return VerificationStatus.NEEDS_REVIEW
        elif not is_exploitable and confidence_num >= 80:
            # é«˜ç½®ä¿¡åº¦è¯´ä¸å¯åˆ©ç”¨
            if score <= 2:
                return VerificationStatus.FALSE_POSITIVE
            else:
                return VerificationStatus.THEORETICAL
        else:
            return VerificationStatus.NEEDS_REVIEW

    def generate_verification_report(
        self,
        results: Dict[str, List[ExploitVerificationReport]],
        module_name: str = "Unknown"
    ) -> str:
        """ç”Ÿæˆå®Œæ•´çš„æ¼æ´éªŒè¯æŠ¥å‘Š"""
        lines = []
        lines.append("=" * 70)
        lines.append("        ğŸ© WHITE HAT VULNERABILITY VERIFICATION REPORT")
        lines.append("=" * 70)
        lines.append("")
        lines.append(f"ğŸ“¦ Module: {module_name}")
        lines.append(f"ğŸ” Total Findings Analyzed: {sum(len(v) for v in results.values())}")
        lines.append("")

        # ç»Ÿè®¡æ‘˜è¦
        lines.append("-" * 70)
        lines.append("ğŸ“Š VERIFICATION SUMMARY")
        lines.append("-" * 70)
        lines.append(f"   ğŸ”´ Verified Vulnerabilities: {len(results.get('verified', []))}")
        lines.append(f"   ğŸŸ  Likely Vulnerabilities: {len(results.get('likely', []))}")
        lines.append(f"   ğŸŸ¡ Needs Manual Review: {len(results.get('needs_review', []))}")
        lines.append(f"   âšª Theoretical (Low Risk): {len(results.get('theoretical', []))}")
        lines.append(f"   ğŸŸ¢ False Positives: {len(results.get('false_positive', []))}")
        lines.append("")

        # å·²éªŒè¯çš„æ¼æ´
        if results.get('verified'):
            lines.append("=" * 70)
            lines.append("            ğŸ”´ VERIFIED VULNERABILITIES")
            lines.append("=" * 70)
            for report in results['verified']:
                lines.append(report.to_markdown())
                lines.append("-" * 70)

        # å¾ˆå¯èƒ½çš„æ¼æ´
        if results.get('likely'):
            lines.append("")
            lines.append("=" * 70)
            lines.append("            ğŸŸ  LIKELY VULNERABILITIES")
            lines.append("=" * 70)
            for report in results['likely']:
                lines.append(report.to_markdown())
                lines.append("-" * 70)

        # éœ€è¦å®¡æŸ¥
        if results.get('needs_review'):
            lines.append("")
            lines.append("=" * 70)
            lines.append("            ğŸŸ¡ NEEDS MANUAL REVIEW")
            lines.append("=" * 70)
            for report in results['needs_review']:
                lines.append(f"### {report.vulnerability_id}")
                lines.append(f"**ç±»å‹**: {report.vulnerability_type}")
                lines.append(f"**è¯„åˆ†**: {report.exploitability_score}/10")
                lines.append(f"**åŸå› **: {report.why_not_exploitable or 'éœ€è¦äººå·¥åˆ¤æ–­'}")
                lines.append("-" * 70)

        # ç†è®ºæ€§æ¼æ´ï¼ˆæŠ˜å ï¼‰
        if results.get('theoretical'):
            lines.append("")
            lines.append("=" * 70)
            lines.append("            âšª THEORETICAL VULNERABILITIES (Low Priority)")
            lines.append("=" * 70)
            for report in results['theoretical']:
                lines.append(f"   â€¢ {report.vulnerability_id}: {report.vulnerability_type}")
                lines.append(f"     Reason: {report.why_not_exploitable or 'No clear exploit path'}")

        # è¯¯æŠ¥ï¼ˆæŠ˜å ï¼‰
        if results.get('false_positive'):
            lines.append("")
            lines.append("=" * 70)
            lines.append("            ğŸŸ¢ FALSE POSITIVES")
            lines.append("=" * 70)
            for report in results['false_positive']:
                lines.append(f"   âœ“ {report.vulnerability_id}: {report.vulnerability_type}")

        lines.append("")
        lines.append("=" * 70)
        lines.append("ğŸ’¡ NOTE: Verified and Likely vulnerabilities should be fixed immediately.")
        lines.append("   Needs Review items require manual investigation.")
        lines.append("=" * 70)

        return "\n".join(lines)


# ============================================================================
# é›†æˆåˆ°å®Œæ•´å®¡è®¡æµç¨‹
# ============================================================================

class EnhancedSecurityAuditPipeline:
    """
    å¢å¼ºç‰ˆå®‰å…¨å®¡è®¡ç®¡é“

    å®Œæ•´æµç¨‹:
    1. SecurityScanner - æ¼æ´æ‰«æ
    2. WhiteHatAgent - æ¼æ´éªŒè¯
    3. SecurityReviewer - Spec è¦†ç›–åˆ†æ
    4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    """

    def __init__(self, scanner, rag_retriever=None):
        """
        Args:
            scanner: SecurityScanner å®ä¾‹
            rag_retriever: RAG æ£€ç´¢å™¨
        """
        self.scanner = scanner
        self.white_hat = WhiteHatAgent(rag_retriever=rag_retriever)

    def audit(
        self,
        source_code: str,
        verified_spec: Optional[str] = None,
        context: Optional[Dict] = None
    ) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´å®¡è®¡

        Args:
            source_code: æºä»£ç 
            verified_spec: å·²éªŒè¯çš„ spec ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
            context: é¢å¤–ä¸Šä¸‹æ–‡

        Returns:
            å®Œæ•´å®¡è®¡æŠ¥å‘Š
        """
        print("ğŸ” [Pipeline] Stage 1: æ¼æ´æ‰«æ...")
        scan_report = self.scanner.scan(source_code)

        if not scan_report.matches:
            print("âœ… [Pipeline] æœªå‘ç°æ¼æ´ï¼Œå®¡è®¡å®Œæˆã€‚")
            return {
                "status": "clean",
                "scan_findings": 0,
                "verified_vulnerabilities": [],
                "theoretical_vulnerabilities": [],
                "false_positives": [],
                "report": "No vulnerabilities found."
            }

        print(f"   å‘ç° {len(scan_report.matches)} ä¸ªæ½œåœ¨æ¼æ´")

        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        vulnerabilities = []
        for match in scan_report.matches:
            vulnerabilities.append({
                "id": match.pattern_id,
                "pattern_id": match.pattern_id,
                "category": match.category if hasattr(match, 'category') else "unknown",
                "severity": match.severity,
                "description": match.recommendation,
                "detection_cues": match.matched_cues,
                "location": {
                    "module": context.get("module_name", "unknown") if context else "unknown",
                    "line_hints": match.line_hints
                }
            })

        print("\nğŸ© [Pipeline] Stage 2: æ¼æ´éªŒè¯...")
        verification_results = self.white_hat.verify_all(
            vulnerabilities=vulnerabilities,
            source_code=source_code,
            context=context
        )

        # ç”ŸæˆæŠ¥å‘Š
        module_name = context.get("module_name", "Unknown") if context else "Unknown"
        report = self.white_hat.generate_verification_report(
            verification_results,
            module_name=module_name
        )

        # è®¡ç®—é£é™©è¯„åˆ†
        verified_count = len(verification_results.get('verified', []))
        likely_count = len(verification_results.get('likely', []))

        if verified_count > 0:
            risk_level = "CRITICAL" if any(r.severity == "critical" for r in verification_results['verified']) else "HIGH"
        elif likely_count > 0:
            risk_level = "HIGH" if any(r.severity in ["critical", "high"] for r in verification_results['likely']) else "MEDIUM"
        else:
            risk_level = "LOW"

        return {
            "status": "vulnerabilities_found",
            "risk_level": risk_level,
            "scan_findings": len(scan_report.matches),
            "verified_vulnerabilities": [asdict(r) if hasattr(r, '__dict__') else r for r in verification_results.get('verified', [])],
            "likely_vulnerabilities": [asdict(r) if hasattr(r, '__dict__') else r for r in verification_results.get('likely', [])],
            "needs_review": [asdict(r) if hasattr(r, '__dict__') else r for r in verification_results.get('needs_review', [])],
            "theoretical_vulnerabilities": [asdict(r) if hasattr(r, '__dict__') else r for r in verification_results.get('theoretical', [])],
            "false_positives": [asdict(r) if hasattr(r, '__dict__') else r for r in verification_results.get('false_positive', [])],
            "report": report,
            "summary": {
                "total_scanned": len(scan_report.matches),
                "verified": verified_count,
                "likely": likely_count,
                "needs_review": len(verification_results.get('needs_review', [])),
                "theoretical": len(verification_results.get('theoretical', [])),
                "false_positive": len(verification_results.get('false_positive', [])),
                "verification_rate": (verified_count + likely_count) / max(1, len(scan_report.matches))
            }
        }
