"""
å®‰å…¨æ¨¡å¼æ‰«æå™¨ (Security Pattern Scanner)

å¯¹ Move ä»£ç è¿›è¡Œå®‰å…¨æ¨¡å¼åŒ¹é…ï¼Œæ£€æµ‹æ½œåœ¨æ¼æ´é£é™©ã€‚
å³ä½¿ä»£ç é€šè¿‡å½¢å¼åŒ–éªŒè¯ï¼Œä¹Ÿèƒ½å‘ç°è§„èŒƒå±‚é¢çš„å®‰å…¨éšæ‚£ã€‚

æ”¯æŒä¸¤ç§åŒ¹é…æ¨¡å¼:
1. å…³é”®è¯/æ­£åˆ™åŒ¹é… (åŸºäº JSONL)
2. è¯­ä¹‰å‘é‡æ£€ç´¢ (åŸºäº ChromaDB)

Usage:
    from src.security.pattern_scan import SecurityScanner

    scanner = SecurityScanner(use_vector_db=True)
    report = scanner.scan(code)
    print(report.to_markdown())
"""

import json
import re
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# å¯¼å…¥é…ç½®
from src.config import DASHSCOPE_API_KEY

# Jinja2 æ¨¡æ¿æ¸²æŸ“ (å¯é€‰)
try:
    from jinja2 import Environment, FileSystemLoader
    JINJA2_AVAILABLE = True
except ImportError:
    JINJA2_AVAILABLE = False

# å¯é€‰ä¾èµ–ï¼šå‘é‡æ£€ç´¢
try:
    from langchain_chroma import Chroma
    from langchain_community.embeddings import DashScopeEmbeddings
    VECTOR_DB_AVAILABLE = True
except ImportError:
    Chroma = None
    DashScopeEmbeddings = None
    VECTOR_DB_AVAILABLE = False

# ==============================================================================
# ä¸¥é‡æ€§æƒé‡ (ç”¨äºé£é™©è¯„åˆ†)
# ==============================================================================

SEVERITY_WEIGHTS = {
    "critical": 100,
    "high": 70,
    "medium": 40,
    "low": 20,
    "advisory": 10,
}

# ==============================================================================
# å†…ç½®å®‰å…¨è§„åˆ™ (ä¸ä¾èµ–å¤–éƒ¨ JSONL)
# ==============================================================================

BUILTIN_RULES = [
    {
        "id": "BUILTIN-001",
        "title": "Potential Arithmetic Overflow",
        "severity": "high",
        "issue_tags": ["overflow", "math_safety"],
        "detection_cues": ["* ", "amount *", "value *", "price *", "fee *"],
        "pattern": r"\b\w+\s*\*\s*\w+",
        "recommendation": "Use u128 casting or add overflow checks with requires()",
        "suggested_checks": ["requires((a as u128) * (b as u128) <= MAX_U64)"],
    },
    {
        "id": "BUILTIN-002",
        "title": "Missing Access Control Check",
        "severity": "high",
        "issue_tags": ["access_control", "privilege"],
        "detection_cues": ["admin", "owner", "cap"],
        "pattern": r"public\s+fun\s+\w+.*(?:admin|set_|update_|remove_|add_)",
        "recommendation": "Ensure AdminCap or ownership verification is required",
        "suggested_checks": ["requires(caller == admin)"],
    },
    {
        "id": "BUILTIN-003",
        "title": "Unchecked Division (Potential Div-by-Zero)",
        "severity": "medium",
        "issue_tags": ["div_zero", "math_safety"],
        "detection_cues": ["/", "div"],
        "pattern": r"\b\w+\s*/\s*\w+",
        "recommendation": "Add requires(divisor != 0) or use safe_div",
        "suggested_checks": ["requires(divisor != 0)"],
    },
    {
        "id": "BUILTIN-004",
        "title": "Flash Loan Without Proper Repayment Check",
        "severity": "high",
        "issue_tags": ["flash_loan", "defi"],
        "detection_cues": ["flash", "loan", "borrow", "repay", "receipt"],
        "pattern": r"(flash|loan|borrow).*receipt",
        "recommendation": "Ensure Receipt is properly validated and consumed",
        "suggested_checks": ["ensures(repaid_amount >= borrowed_amount + fee)"],
    },
    {
        "id": "BUILTIN-005",
        "title": "Oracle Price Manipulation Risk",
        "severity": "high",
        "issue_tags": ["oracle", "price_manipulation"],
        "detection_cues": ["oracle", "price", "pyth", "get_price"],
        "pattern": r"(get_price|oracle|price_feed)",
        "recommendation": "Use TWAP, check staleness, and verify confidence intervals",
        "suggested_checks": ["requires(price_timestamp > now - MAX_STALENESS)"],
    },
    {
        "id": "BUILTIN-006",
        "title": "Linear Resource Not Properly Handled",
        "severity": "medium",
        "issue_tags": ["linear_resource", "type_safety"],
        "detection_cues": ["coin", "balance", "receipt"],
        "pattern": r"(Coin<|Balance<|Receipt)",
        "recommendation": "Ensure linear resources are returned, consumed, or destructured",
        "suggested_checks": ["ensures(resource_consumed OR resource_returned)"],
    },
    {
        "id": "BUILTIN-007",
        "title": "Missing Input Validation",
        "severity": "low",
        "issue_tags": ["validation", "input_check"],
        "detection_cues": ["amount", "value", "rate", "bps"],
        "pattern": r"public\s+fun\s+\w+\s*\([^)]*(?:amount|value|rate)",
        "recommendation": "Add requires(amount > 0) and upper bound checks",
        "suggested_checks": ["requires(amount > 0)", "requires(rate <= MAX_RATE)"],
    },
    {
        "id": "BUILTIN-008",
        "title": "Liquidation Logic Risk",
        "severity": "high",
        "issue_tags": ["liquidation", "defi", "lending"],
        "detection_cues": ["liquidat", "collateral", "health", "ratio"],
        "pattern": r"(liquidat|health_factor|collateral_ratio)",
        "recommendation": "Verify liquidation threshold and penalty calculations",
        "suggested_checks": ["requires(health_factor < LIQUIDATION_THRESHOLD)"],
    },
    # =========================================================================
    # Sui Move é€šç”¨å®‰å…¨è§„åˆ™ (BUILTIN-009 ~ BUILTIN-016)
    # =========================================================================
    {
        "id": "BUILTIN-009",
        "title": "Shared Object Without Access Control",
        "severity": "high",
        "issue_tags": ["access_control", "shared_object", "sui"],
        "detection_cues": ["&mut ", "public fun", "entry fun"],
        "pattern": r"public\s+(entry\s+)?fun\s+\w+[^{]*&mut\s+\w+",
        "recommendation": "Add AdminCap/OwnerCap parameter or assert sender check for shared object mutations",
        "suggested_checks": ["requires(tx_context::sender(ctx) == admin)", "requires(has_capability)"],
    },
    {
        "id": "BUILTIN-010",
        "title": "Coin Type Confusion",
        "severity": "high",
        "issue_tags": ["type_safety", "coin", "sui"],
        "detection_cues": ["Coin<T>", "Balance<T>", "<T>"],
        "pattern": r"fun\s+\w+<\s*T\s*>[^{]*(?:Coin|Balance)<\s*T\s*>",
        "recommendation": "Verify generic coin type T against expected type or whitelist",
        "suggested_checks": ["requires(type_name::get<T>() == expected_type)"],
    },
    {
        "id": "BUILTIN-011",
        "title": "Object Ownership Transfer Risk",
        "severity": "high",
        "issue_tags": ["ownership", "transfer", "sui"],
        "detection_cues": ["transfer::", "public_transfer", "share_object"],
        "pattern": r"(transfer::public_transfer|transfer::share_object)\s*\(",
        "recommendation": "Verify recipient and ensure ownership transfer is intentional",
        "suggested_checks": ["Validate recipient address", "Check transfer authorization"],
    },
    {
        "id": "BUILTIN-012",
        "title": "Capability Leak via Public Transfer",
        "severity": "high",
        "issue_tags": ["capability", "access_control", "sui"],
        "detection_cues": ["Cap", "Capability", "public_transfer"],
        "pattern": r"public_transfer\s*\([^)]*Cap",
        "recommendation": "Capabilities should not be freely transferable; remove store ability or restrict transfer",
        "suggested_checks": ["Capability should not have 'store' ability", "Use transfer::transfer instead"],
    },
    {
        "id": "BUILTIN-013",
        "title": "Clock/Timestamp Manipulation Risk",
        "severity": "medium",
        "issue_tags": ["timestamp", "clock", "sui"],
        "detection_cues": ["clock", "timestamp", "Clock", "timestamp_ms"],
        "pattern": r"clock::timestamp_ms|&Clock",
        "recommendation": "Be aware validators can slightly manipulate timestamps; use time windows instead of exact comparisons",
        "suggested_checks": ["Use tolerance window for time checks", "requires(current_time >= start_time - TOLERANCE)"],
    },
    {
        "id": "BUILTIN-014",
        "title": "Flash Loan Callback Order",
        "severity": "high",
        "issue_tags": ["flash_loan", "hot_potato", "sui"],
        "detection_cues": ["flash", "borrow", "repay", "Receipt"],
        "pattern": r"public\s+fun\s+(flash_|borrow)[^}]+Receipt",
        "recommendation": "Use Hot Potato pattern - return Receipt that must be consumed in same transaction",
        "suggested_checks": ["Receipt has no drop/store ability", "repay() consumes Receipt"],
    },
    {
        "id": "BUILTIN-015",
        "title": "BCS Deserialization Without Validation",
        "severity": "medium",
        "issue_tags": ["deserialization", "external_data", "sui"],
        "detection_cues": ["bcs::", "from_bytes", "deserialize"],
        "pattern": r"bcs::(from_bytes|to_bytes)|deserialize",
        "recommendation": "Validate deserialized data before use; external data may be malformed",
        "suggested_checks": ["Validate struct fields after deserialization", "Check data bounds"],
    },
    {
        "id": "BUILTIN-016",
        "title": "Reentrancy via Shared Object",
        "severity": "high",
        "issue_tags": ["reentrancy", "shared_object", "sui"],
        "detection_cues": ["&mut ", "external call", "callback"],
        "pattern": r"public\s+fun\s+\w+[^{]*&mut[^{]+\w+::\w+\s*\(",
        "recommendation": "Update state before external calls; use reentrancy guard for shared objects",
        "suggested_checks": ["Follow checks-effects-interactions pattern", "requires(!is_locked)"],
    },
    # =========================================================================
    # é—ªç”µè´·ç±»å‹æ··æ·†æ¼æ´ (BUILTIN-017 ~ BUILTIN-018) - v2.5.4 æ–°å¢
    # =========================================================================
    {
        "id": "BUILTIN-017",
        "title": "Flash Loan Repayment Type Confusion",
        "severity": "critical",
        "issue_tags": ["flash_loan", "type_safety", "defi", "sui"],
        "detection_cues": ["flashloan", "flash_loan", "repay", "Receipt", "type_name", "Coin<"],
        "pattern": r"(repay|flash).*<\s*\w+\s*>.*Coin<\s*\w+\s*>",
        "recommendation": "Verify repayment coin type matches borrowed coin type: assert!(type_name::get<A>() == receipt.type_name)",
        "suggested_checks": [
            "repay å‡½æ•°å¿…é¡»éªŒè¯: type_name::get<A>().into_string() == receipt.type_name",
            "æ£€æŸ¥: contains_type åªéªŒè¯æ± å­é‡Œæœ‰è¯¥å¸ï¼Œä¸éªŒè¯æ˜¯å¦æ˜¯å€Ÿå‡ºçš„å¸",
            "æ¼æ´æ¨¡å¼: å€Ÿ CoinA è¿˜ CoinB â†’ æç©º CoinA æ± "
        ],
    },
    {
        "id": "BUILTIN-018",
        "title": "Hot Potato Receipt Without Type Verification",
        "severity": "critical",
        "issue_tags": ["flash_loan", "hot_potato", "type_safety", "sui"],
        "detection_cues": ["Receipt", "FlashReceipt", "repay", "pool_id", "amount"],
        "pattern": r"struct\s+\w*Receipt\s*\{[^}]*pool_id[^}]*\}",
        "recommendation": "Receipt must store borrowed coin type_name and repay must verify it matches",
        "suggested_checks": [
            "Receipt åº”åŒ…å«: type_name: TypeName (å€Ÿå‡ºå¸ç§ç±»å‹)",
            "repay åº”éªŒè¯: type_name::get<RepaidCoin>() == receipt.type_name",
            "ä»…æ£€æŸ¥ pool_id å’Œ amount ä¸å¤Ÿï¼Œå¿…é¡»éªŒè¯å¸ç§"
        ],
    },
]


# ==============================================================================
# æ•°æ®ç±»å‹å®šä¹‰
# ==============================================================================

@dataclass
class PatternMatch:
    """å•ä¸ªæ¨¡å¼åŒ¹é…ç»“æœ"""
    pattern_id: str
    title: str
    severity: str
    issue_tags: List[str]
    description: str  # é£é™©åˆ†æ/æ¼æ´è¯¦æƒ…
    recommendation: str  # ä¿®å¤å»ºè®®
    suggested_checks: List[str]
    matched_cues: List[str]
    confidence: float  # 0.0 - 1.0
    line_hints: List[int]  # å¯èƒ½ç›¸å…³çš„è¡Œå·


@dataclass
class ScanReport:
    """æ‰«ææŠ¥å‘Š"""
    total_patterns_checked: int
    matches: List[PatternMatch] = field(default_factory=list)
    risk_score: int = 0
    summary: str = ""

    def to_markdown(self) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        if not self.matches:
            return "## Security Scan Report\n\nâœ… No potential issues detected.\n"

        lines = [
            "## Security Scan Report",
            "",
            f"**Risk Score:** {self.risk_score}/100",
            f"**Issues Found:** {len(self.matches)}",
            "",
            "### Findings",
            "",
        ]

        # æŒ‰ä¸¥é‡æ€§æ’åº
        sorted_matches = sorted(
            self.matches,
            key=lambda m: SEVERITY_WEIGHTS.get(m.severity, 0),
            reverse=True
        )

        for i, m in enumerate(sorted_matches, 1):
            severity_emoji = {
                "critical": "ğŸ”´",
                "high": "ğŸŸ ",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢",
                "advisory": "ğŸ”µ",
            }.get(m.severity, "âšª")

            lines.append(f"#### {i}. {severity_emoji} [{m.severity.upper()}] {m.title}")
            lines.append(f"- **ID:** `{m.pattern_id}`")
            lines.append(f"- **Tags:** {', '.join(m.issue_tags)}")
            lines.append(f"- **Confidence:** {m.confidence:.0%}")
            if m.matched_cues:
                lines.append(f"- **Matched Cues:** `{', '.join(m.matched_cues[:5])}`")
            lines.append(f"- **Recommendation:** {m.recommendation}")
            if m.suggested_checks:
                lines.append("- **Suggested Spec Checks:**")
                for check in m.suggested_checks[:3]:
                    lines.append(f"  - `{check}`")
            lines.append("")

        return "\n".join(lines)

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸ (ç”¨äº JSON è¾“å‡º)"""
        return {
            "risk_score": self.risk_score,
            "total_patterns_checked": self.total_patterns_checked,
            "issues_count": len(self.matches),
            "matches": [
                {
                    "pattern_id": m.pattern_id,
                    "title": m.title,
                    "severity": m.severity,
                    "issue_tags": m.issue_tags,
                    "confidence": m.confidence,
                    "recommendation": m.recommendation,
                }
                for m in self.matches
            ],
        }

    def get_high_priority_warnings(self) -> List[str]:
        """è·å–é«˜ä¼˜å…ˆçº§è­¦å‘Š (ç”¨äºæ³¨å…¥åˆ° Prompt)"""
        warnings = []
        for m in self.matches:
            if m.severity in ["critical", "high"]:
                warning = f"[âš ï¸ {m.severity.upper()}] {m.title}: {m.recommendation}"
                if m.suggested_checks:
                    warning += f" Suggested: {m.suggested_checks[0]}"
                warnings.append(warning)
        return warnings[:5]  # é™åˆ¶æ•°é‡


# ==============================================================================
# å®‰å…¨æ‰«æå™¨
# ==============================================================================

class SecurityScanner:
    """
    å®‰å…¨æ¨¡å¼æ‰«æå™¨

    ç»“åˆå†…ç½®è§„åˆ™ã€å¤–éƒ¨ JSONL çŸ¥è¯†åº“å’Œå‘é‡è¯­ä¹‰æ£€ç´¢ï¼Œå¯¹ Move ä»£ç è¿›è¡Œå®‰å…¨åˆ†æã€‚
    """

    def __init__(
        self,
        patterns_path: Optional[str] = None,
        use_vector_db: bool = True,
        vector_db_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–æ‰«æå™¨

        Args:
            patterns_path: å¤–éƒ¨ JSONL æ–‡ä»¶è·¯å¾„ (å¯é€‰)
            use_vector_db: æ˜¯å¦å¯ç”¨å‘é‡è¯­ä¹‰æ£€ç´¢ (é»˜è®¤ True)
            vector_db_path: å‘é‡åº“è·¯å¾„ (å¯é€‰)
        """
        self.external_patterns = self._load_external_patterns(patterns_path)
        self.all_patterns = BUILTIN_RULES + self.external_patterns

        # åˆå§‹åŒ–å‘é‡æ£€ç´¢
        self.vector_db = None
        self.use_vector_db = use_vector_db and VECTOR_DB_AVAILABLE
        if self.use_vector_db:
            self.vector_db = self._init_vector_db(vector_db_path)

        vector_status = f"+ å‘é‡æ£€ç´¢ ({'å¯ç”¨' if self.vector_db else 'ç¦ç”¨'})"
        print(f"ğŸ”’ [SecurityScanner] å·²åŠ è½½ {len(BUILTIN_RULES)} æ¡å†…ç½®è§„åˆ™ + {len(self.external_patterns)} æ¡å¤–éƒ¨æ¨¡å¼ {vector_status}")

    def _init_vector_db(self, vector_db_path: Optional[str] = None) -> Optional[object]:
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“è¿æ¥

        è‡ªåŠ¨æ£€æµ‹ embedding ç±»å‹ï¼š
        1. ä¼˜å…ˆä½¿ç”¨æœ¬åœ° HuggingFace æ¨¡å‹ï¼ˆå¦‚æœ security_patterns_local å­˜åœ¨ï¼‰
        2. å¦åˆ™ä½¿ç”¨ DashScope APIï¼ˆå¦‚æœæœ‰ API Keyï¼‰
        """
        if not VECTOR_DB_AVAILABLE:
            return None

        base_path = Path(__file__).resolve().parents[2] / "data" / "vector_store"

        # 1. ä¼˜å…ˆæ£€æŸ¥æœ¬åœ°æ¨¡å‹å‘é‡åº“
        local_db_path = base_path / "security_patterns_local"
        if local_db_path.exists():
            try:
                from langchain_huggingface import HuggingFaceEmbeddings
                # æ¨¡å‹ç¼“å­˜åˆ°é¡¹ç›®ç›®å½•ä¸‹
                model_cache_dir = base_path.parent / "models"
                embeddings = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/all-MiniLM-L6-v2",
                    cache_folder=str(model_cache_dir),
                    model_kwargs={'device': 'cpu', 'local_files_only': True},
                    encode_kwargs={'normalize_embeddings': True}
                )
                db = Chroma(
                    persist_directory=str(local_db_path),
                    embedding_function=embeddings,
                    collection_name="security_patterns"
                )
                print("ğŸ“¦ [SecurityScanner] ä½¿ç”¨æœ¬åœ° HuggingFace embedding å‘é‡åº“")
                return db
            except ImportError:
                pass  # æœ¬åœ°æ¨¡å‹ä¸å¯ç”¨ï¼Œç»§ç»­å°è¯• DashScope
            except Exception as e:
                print(f"âš ï¸  [SecurityScanner] æœ¬åœ°å‘é‡åº“åˆå§‹åŒ–å¤±è´¥: {e}")

        # 2. å›é€€åˆ° DashScope API
        if not DASHSCOPE_API_KEY:
            print("âš ï¸  [SecurityScanner] æœªæ‰¾åˆ° DASHSCOPE_API_KEY ä¸”æ— æœ¬åœ°å‘é‡åº“ï¼Œç¦ç”¨å‘é‡æ£€ç´¢")
            return None

        api_db_path = Path(vector_db_path) if vector_db_path else (base_path / "security_patterns")

        if not api_db_path.exists():
            print(f"âš ï¸  [SecurityScanner] å‘é‡åº“ä¸å­˜åœ¨: {api_db_path}ï¼Œç¦ç”¨å‘é‡æ£€ç´¢")
            return None

        try:
            embeddings = DashScopeEmbeddings(model="text-embedding-v2", dashscope_api_key=DASHSCOPE_API_KEY)
            db = Chroma(
                persist_directory=str(api_db_path),
                embedding_function=embeddings,
                collection_name="security_patterns"
            )
            print("â˜ï¸  [SecurityScanner] ä½¿ç”¨ DashScope API å‘é‡åº“")
            return db
        except Exception as e:
            print(f"âš ï¸  [SecurityScanner] å‘é‡åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            return None

    def _load_external_patterns(self, path: Optional[str]) -> List[Dict]:
        """åŠ è½½å¤–éƒ¨ JSONL æ¨¡å¼"""
        default_path = Path(__file__).resolve().parents[2] / "reports" / "datasets" / "security_patterns.jsonl"
        target_path = Path(path) if path else default_path

        if not target_path.exists():
            return []

        patterns = []
        with target_path.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    patterns.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        return patterns

    def scan(
        self,
        code: str,
        domain_hint: Optional[str] = None,
        function_hints: Optional[List[str]] = None,
    ) -> ScanReport:
        """
        æ‰«æä»£ç ï¼Œè¿”å›å®‰å…¨æŠ¥å‘Š

        Args:
            code: Move æºä»£ç 
            domain_hint: é¢†åŸŸæç¤º (å¦‚ "lending", "amm")
            function_hints: å‡½æ•°åæç¤ºåˆ—è¡¨
        """
        matches: List[PatternMatch] = []
        code_lower = code.lower()

        # 1. å…³é”®è¯/æ­£åˆ™åŒ¹é…
        for pattern in self.all_patterns:
            match_result = self._match_pattern(code, code_lower, pattern, domain_hint, function_hints)
            if match_result:
                matches.append(match_result)

        # 2. å‘é‡è¯­ä¹‰æ£€ç´¢ (å¦‚æœå¯ç”¨)
        if self.vector_db:
            vector_matches = self._semantic_search(code, domain_hint)
            matches.extend(vector_matches)

        # å»é‡ (æŒ‰ title)
        seen_titles = set()
        unique_matches = []
        for m in matches:
            if m.title not in seen_titles:
                seen_titles.add(m.title)
                unique_matches.append(m)

        # è®¡ç®—é£é™©åˆ†æ•°
        risk_score = self._calculate_risk_score(unique_matches)

        report = ScanReport(
            total_patterns_checked=len(self.all_patterns),
            matches=unique_matches,
            risk_score=risk_score,
            summary=self._generate_summary(unique_matches, risk_score),
        )

        return report

    def _semantic_search(self, code: str, domain_hint: Optional[str] = None, top_k: int = 5) -> List[PatternMatch]:
        """ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢"""
        if not self.vector_db:
            return []

        try:
            # æ„å»ºæŸ¥è¯¢ï¼šä»£ç ç‰‡æ®µ + é¢†åŸŸæç¤º
            query = code[:2000]  # é™åˆ¶é•¿åº¦
            if domain_hint:
                query = f"[{domain_hint}] {query}"

            # æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£
            results = self.vector_db.similarity_search_with_score(query, k=top_k * 2)  # å¤šæ£€ç´¢ä¸€äº›ï¼Œåé¢ä¼šè¿‡æ»¤

            matches = []
            code_lower = code.lower()

            for doc, score in results:
                # score æ˜¯è·ç¦»ï¼Œè¶Šå°è¶Šç›¸ä¼¼
                # è½¬æ¢ä¸ºç½®ä¿¡åº¦ (0-1)ï¼Œè·ç¦» < 1.0 è®¤ä¸ºæ˜¯é«˜ç›¸ä¼¼åº¦
                confidence = max(0, min(1, 1 - score / 2))

                # åªä¿ç•™ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜çš„ç»“æœ (è·ç¦» < 1.5)
                if score > 1.5:
                    continue

                metadata = doc.metadata
                title = metadata.get("title", "Unknown Issue")
                description = metadata.get("description", "")
                function_hint = metadata.get("function", "")
                detection_cues = metadata.get("detection_cues", "")

                # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šéªŒè¯ä»£ç ç›¸å…³æ€§
                # æ£€æŸ¥æ¼æ´æè¿°ä¸­çš„å…³é”®å…ƒç´ æ˜¯å¦åœ¨å½“å‰ä»£ç ä¸­å­˜åœ¨
                relevance_score = self._check_code_relevance(
                    code_lower=code_lower,
                    title=title,
                    description=description,
                    function_hint=function_hint,
                    detection_cues=detection_cues
                )

                # å¦‚æœç›¸å…³æ€§å¤ªä½ï¼Œè·³è¿‡è¿™ä¸ªæ¼æ´
                if relevance_score < 0.3:
                    continue

                # è°ƒæ•´ç½®ä¿¡åº¦ (ç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œä»£ç ç›¸å…³æ€§)
                adjusted_confidence = confidence * relevance_score

                severity = metadata.get("severity", "low")

                # æ‰¾åˆ°å®é™…åŒ¹é…çš„ cues
                matched_cues = self._find_matched_cues(code_lower, detection_cues, title)

                matches.append(PatternMatch(
                    pattern_id=f"VEC-{metadata.get('id', 'UNKNOWN')}",
                    title=title,
                    severity=severity if severity else "low",
                    issue_tags=metadata.get("issue_tags", "").split(" | ") if metadata.get("issue_tags") else [],
                    description=description,  # é£é™©åˆ†æ
                    recommendation=metadata.get("recommendation", ""),
                    suggested_checks=[],
                    matched_cues=matched_cues if matched_cues else ["semantic_match"],
                    confidence=adjusted_confidence,
                    line_hints=[],
                ))

            return matches[:top_k]  # é™åˆ¶è¿”å›æ•°é‡
        except Exception as e:
            print(f"âš ï¸  [SecurityScanner] å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _check_code_relevance(
        self,
        code_lower: str,
        title: str,
        description: str,
        function_hint: str,
        detection_cues: str
    ) -> float:
        """
        æ£€æŸ¥æ¼æ´ä¸å½“å‰ä»£ç çš„ç›¸å…³æ€§

        Returns:
            ç›¸å…³æ€§åˆ†æ•° 0.0 - 1.0
        """
        relevance = 0.0
        checks = 0
        negative_hits = 0  # è´Ÿé¢åŒ¹é…ï¼ˆæè¿°ä¸­æåˆ°ä½†ä»£ç ä¸­ä¸å­˜åœ¨çš„æ¨¡å¼ï¼‰
        critical_missing = 0  # æ ¸å¿ƒæ¦‚å¿µç¼ºå¤±

        # 0. æå–æ ‡é¢˜ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼ˆè¿™äº›å¿…é¡»åœ¨ä»£ç ä¸­å­˜åœ¨ï¼‰
        # ä¾‹å¦‚ "Fee Recipient" -> recipient å¿…é¡»å­˜åœ¨
        core_concepts = self._extract_core_concepts(title)
        for concept in core_concepts:
            if concept not in code_lower:
                critical_missing += 1

        # å¦‚æœæ ¸å¿ƒæ¦‚å¿µä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›å¾ˆä½çš„åˆ†æ•°
        if critical_missing > 0:
            return 0.1  # æ ¸å¿ƒæ¦‚å¿µç¼ºå¤±ï¼ŒåŸºæœ¬åˆ¤å®šä¸ºä¸ç›¸å…³

        # 1. æ£€æŸ¥æ ‡é¢˜ä¸­çš„å…³é”®è¯
        title_keywords = self._extract_keywords(title)
        for kw in title_keywords:
            checks += 1
            if kw in code_lower:
                relevance += 1.0

        # 2. æ£€æŸ¥å‡½æ•°å
        if function_hint:
            func_name = function_hint.split("::")[-1].lower() if "::" in function_hint else function_hint.lower()
            checks += 1
            if func_name in code_lower:
                relevance += 1.5  # å‡½æ•°ååŒ¹é…æƒé‡æ›´é«˜

        # 3. æ£€æŸ¥ detection_cues
        if detection_cues:
            cues = detection_cues.split(" | ") if " | " in detection_cues else [detection_cues]
            for cue in cues[:5]:
                cue_lower = cue.lower().strip()
                if len(cue_lower) >= 3:  # å¿½ç•¥å¤ªçŸ­çš„ cue
                    checks += 1
                    if cue_lower in code_lower:
                        relevance += 0.8

        # 4. ç®€å•ç´¢å¼•æ£€æŸ¥ï¼šæè¿°ä¸­æåˆ°çš„å‡½æ•°/åŠŸèƒ½æ˜¯å¦å­˜åœ¨äºä»£ç ä¸­
        # æå–æè¿°ä¸­çš„å‡½æ•°åï¼ˆä¸‹åˆ’çº¿å‘½åçš„æ ‡è¯†ç¬¦ï¼‰
        mentioned_identifiers = re.findall(r'\b([a-z][a-z0-9]*(?:_[a-z0-9]+)+)\b', description.lower())
        # å»é‡ï¼Œåªä¿ç•™é•¿åº¦>=8çš„ï¼ˆæ›´å…·ä½“çš„æ ‡è¯†ç¬¦ï¼‰
        mentioned_identifiers = list(set([x for x in mentioned_identifiers if len(x) >= 8]))

        # æ£€æŸ¥è¿™äº›æ ‡è¯†ç¬¦æ˜¯å¦åœ¨ä»£ç ä¸­å­˜åœ¨
        missing_count = 0
        for identifier in mentioned_identifiers[:5]:  # åªæ£€æŸ¥å‰5ä¸ª
            if identifier not in code_lower:
                missing_count += 1

        # å¦‚æœå¤§éƒ¨åˆ†æåˆ°çš„æ ‡è¯†ç¬¦éƒ½ä¸å­˜åœ¨ï¼Œå¾ˆå¯èƒ½æ˜¯è¯¯æŠ¥
        if len(mentioned_identifiers) >= 2 and missing_count >= len(mentioned_identifiers) * 0.7:
            return 0.15  # å¤§æ¦‚ç‡è¯¯æŠ¥

        # 5. æ£€æŸ¥æè¿°ä¸­çš„ä»£ç æ¨¡å¼ï¼ˆæ­£é¢å’Œè´Ÿé¢ï¼‰
        code_patterns = re.findall(r'`([^`]+)`', description)
        # åŒæ—¶æ£€æŸ¥æ¨èä¸­æåˆ°çš„ç‰¹å®šå˜é‡å/å‡½æ•°å
        specific_names = re.findall(r'\b([a-z_]+(?:_[a-z]+)+)\b', description.lower())
        all_patterns = list(set(code_patterns + specific_names))

        for pattern in all_patterns[:10]:
            pattern_lower = pattern.lower()
            if len(pattern_lower) >= 5:  # åªæ£€æŸ¥æœ‰æ„ä¹‰çš„é•¿æ¨¡å¼
                checks += 1
                if pattern_lower in code_lower:
                    relevance += 0.6
                else:
                    # å¦‚æœæ˜¯å¾ˆå…·ä½“çš„å˜é‡åï¼ˆå«ä¸‹åˆ’çº¿ï¼‰ï¼Œä½†ä»£ç ä¸­ä¸å­˜åœ¨ï¼Œæ‰£åˆ†
                    if '_' in pattern_lower and not any(p in code_lower for p in pattern_lower.split('_')):
                        negative_hits += 1

        # è®¡ç®—æœ€ç»ˆç›¸å…³æ€§åˆ†æ•°
        if checks == 0:
            return 0.5  # æ— æ³•åˆ¤æ–­ï¼Œç»™ä¸­ç­‰åˆ†æ•°

        base_score = min(relevance / max(checks * 0.5, 1), 1.0)

        # å¦‚æœæœ‰å¾ˆå¤šè´Ÿé¢åŒ¹é…ï¼Œé™ä½åˆ†æ•°
        if negative_hits >= 2:
            base_score *= 0.5  # ä¸¥é‡é™ä½åˆ†æ•°
        elif negative_hits >= 1:
            base_score *= 0.7

        return base_score

    def _extract_core_concepts(self, title: str) -> List[str]:
        """
        ä»æ ‡é¢˜ä¸­æå–æ ¸å¿ƒæ¦‚å¿µ

        è¿™äº›æ¦‚å¿µå¿…é¡»åœ¨ä»£ç ä¸­å­˜åœ¨ï¼Œå¦åˆ™æ¼æ´ä¸é€‚ç”¨ã€‚
        ä¾‹å¦‚: "Fee Recipient Ignored" -> ["recipient"]
              "Oracle Price Manipulation" -> ["oracle", "price"]
              "Whitelist Bypass" -> ["whitelist"]
        """
        # æ ¸å¿ƒæ¦‚å¿µè¯å…¸ï¼šæ ‡é¢˜å…³é”®è¯ -> ä»£ç ä¸­å¿…é¡»å­˜åœ¨çš„æ¦‚å¿µ
        concept_mapping = {
            'recipient': ['recipient'],
            'oracle': ['oracle'],
            'whitelist': ['whitelist', 'white_list'],
            'blacklist': ['blacklist', 'black_list'],
            'admin': ['admin'],
            'owner': ['owner'],
            'governance': ['governance', 'gov'],
            'timelock': ['timelock', 'time_lock'],
            'pause': ['pause', 'paused'],
            'upgrade': ['upgrade'],
            'proxy': ['proxy'],
            'delegate': ['delegate'],
            'callback': ['callback'],
            'reentrancy': ['reentrant', 'reentrancy'],
            'slippage': ['slippage'],
            'deadline': ['deadline'],
            'nonce': ['nonce'],
            'signature': ['signature', 'sig'],
        }

        title_lower = title.lower()
        required_concepts = []

        for keyword, concepts in concept_mapping.items():
            if keyword in title_lower:
                required_concepts.extend(concepts)

        return required_concepts

    def _extract_keywords(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
        # ç§»é™¤å¸¸è§çš„æ— æ„ä¹‰è¯
        stop_words = {'the', 'is', 'a', 'an', 'in', 'on', 'of', 'for', 'to', 'with', 'without', 'not', 'and', 'or', 'but'}

        words = re.findall(r'\b[a-z_][a-z0-9_]*\b', text.lower())
        keywords = [w for w in words if len(w) >= 3 and w not in stop_words]

        return keywords[:10]

    def _find_matched_cues(self, code_lower: str, detection_cues: str, title: str) -> List[str]:
        """æ‰¾åˆ°å®é™…åŒ¹é…çš„ cues"""
        matched = []

        # ä» detection_cues ä¸­æ‰¾
        if detection_cues:
            cues = detection_cues.split(" | ") if " | " in detection_cues else [detection_cues]
            for cue in cues:
                cue_lower = cue.lower().strip()
                if len(cue_lower) >= 3 and cue_lower in code_lower:
                    matched.append(cue)

        # ä»æ ‡é¢˜ä¸­æ‰¾
        title_keywords = self._extract_keywords(title)
        for kw in title_keywords:
            if kw in code_lower and kw not in [m.lower() for m in matched]:
                matched.append(kw)

        return matched[:5]

    def _match_pattern(
        self,
        code: str,
        code_lower: str,
        pattern: Dict,
        domain_hint: Optional[str],
        function_hints: Optional[List[str]],
    ) -> Optional[PatternMatch]:
        """åŒ¹é…å•ä¸ªæ¨¡å¼"""
        matched_cues = []
        confidence = 0.0
        line_hints = []

        # 1. å…³é”®è¯/Cue åŒ¹é…
        cues = pattern.get("detection_cues") or []
        for cue in cues:
            cue_lower = str(cue).lower()
            if cue_lower and cue_lower in code_lower:
                matched_cues.append(cue)
                confidence += 0.15

        # 2. æ­£åˆ™æ¨¡å¼åŒ¹é…
        regex_pattern = pattern.get("pattern")
        if regex_pattern:
            try:
                regex_matches = list(re.finditer(regex_pattern, code, re.IGNORECASE))
                if regex_matches:
                    confidence += 0.3
                    # æå–è¡Œå·
                    for m in regex_matches[:3]:
                        line_num = code[:m.start()].count('\n') + 1
                        line_hints.append(line_num)
            except re.error:
                pass

        # 3. æ ‡ç­¾/é¢†åŸŸåŒ¹é…
        issue_tags = pattern.get("issue_tags") or []
        if domain_hint:
            for tag in issue_tags:
                if domain_hint.lower() in tag.lower() or tag.lower() in domain_hint.lower():
                    confidence += 0.2
                    break

        # 4. å‡½æ•°ååŒ¹é…
        if function_hints:
            pattern_func = pattern.get("function")
            if pattern_func:
                for func in function_hints:
                    if func.lower() in pattern_func.lower() or pattern_func.lower() in func.lower():
                        confidence += 0.25
                        break

        # ç½®ä¿¡åº¦é˜ˆå€¼
        if confidence < 0.2 or not matched_cues:
            return None

        confidence = min(confidence, 1.0)

        return PatternMatch(
            pattern_id=pattern.get("id", "UNKNOWN"),
            title=pattern.get("title", "Unknown Issue"),
            severity=pattern.get("severity", "low"),
            issue_tags=issue_tags,
            description=pattern.get("description", ""),  # é£é™©åˆ†æ
            recommendation=pattern.get("recommendation", ""),
            suggested_checks=pattern.get("suggested_checks") or [],
            matched_cues=matched_cues[:5],
            confidence=confidence,
            line_hints=line_hints[:5],
        )

    def _calculate_risk_score(self, matches: List[PatternMatch]) -> int:
        """è®¡ç®—é£é™©åˆ†æ•° (0-100)"""
        if not matches:
            return 0

        total = 0
        for m in matches:
            weight = SEVERITY_WEIGHTS.get(m.severity, 10)
            total += weight * m.confidence

        # å½’ä¸€åŒ–åˆ° 0-100
        return min(int(total), 100)

    def _generate_summary(self, matches: List[PatternMatch], risk_score: int) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        if not matches:
            return "No security concerns detected."

        severity_counts = {}
        for m in matches:
            severity_counts[m.severity] = severity_counts.get(m.severity, 0) + 1

        parts = []
        for sev in ["critical", "high", "medium", "low", "advisory"]:
            if sev in severity_counts:
                parts.append(f"{severity_counts[sev]} {sev}")

        return f"Found {len(matches)} potential issues ({', '.join(parts)}). Risk score: {risk_score}/100"

    def generate_detailed_report(
        self,
        code: str,
        report: ScanReport,
        source_tag: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆè¯¦ç»†çš„å®‰å…¨å®¡è®¡æŠ¥å‘Š

        æ ¼å¼å‚è€ƒä¸“ä¸šå®‰å…¨å®¡è®¡æŠ¥å‘Šï¼ŒåŒ…å«:
        - æ¨¡å—/åˆçº¦åç§°
        - å‡½æ•°ä½ç½®
        - å…·ä½“ä»£ç è¡Œ
        - æ¼æ´æè¿°å’Œå»ºè®®
        """
        lines = []
        lines.append("")
        lines.append("=" * 70)
        lines.append("                    ğŸ”’ SECURITY AUDIT REPORT")
        lines.append("=" * 70)
        lines.append("")

        # è§£æä»£ç è·å–æ¨¡å—å’Œå‡½æ•°ä¿¡æ¯
        module_name = self._extract_module_name(code)
        functions = self._extract_functions(code)

        lines.append(f"ğŸ“¦ Module: {module_name or 'Unknown'}")
        lines.append(f"ğŸ·ï¸  Domain: {source_tag or 'general'}")
        lines.append(f"ğŸ“Š Risk Score: {report.risk_score}/100")
        lines.append(f"ğŸ” Issues Found: {len(report.matches)}")
        lines.append("")
        lines.append("-" * 70)

        # ç»Ÿè®¡ä¸¥é‡æ€§åˆ†å¸ƒ
        severity_counts = {}
        for m in report.matches:
            severity_counts[m.severity] = severity_counts.get(m.severity, 0) + 1

        lines.append("ğŸ“ˆ Severity Distribution:")
        for sev in ["critical", "high", "medium", "low", "advisory"]:
            if sev in severity_counts:
                emoji = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢", "advisory": "ğŸ”µ"}.get(sev, "âšª")
                lines.append(f"   {emoji} {sev.upper()}: {severity_counts[sev]}")
        lines.append("")
        lines.append("=" * 70)
        lines.append("                         FINDINGS")
        lines.append("=" * 70)

        # æŒ‰ä¸¥é‡æ€§æ’åº
        sorted_matches = sorted(
            report.matches,
            key=lambda m: SEVERITY_WEIGHTS.get(m.severity, 0),
            reverse=True
        )

        for i, m in enumerate(sorted_matches, 1):
            severity_emoji = {
                "critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢", "advisory": "ğŸ”µ"
            }.get(m.severity, "âšª")

            lines.append("")
            lines.append(f"â”Œâ”€ {m.pattern_id}: {m.title}")
            lines.append(f"â”‚")
            lines.append(f"â”‚  Severity:   {severity_emoji} {m.severity.upper()}")
            lines.append(f"â”‚  Confidence: {m.confidence:.0%}")
            lines.append(f"â”‚  Tags:       {', '.join(m.issue_tags) if m.issue_tags else 'N/A'}")

            # å®šä½åˆ°å…·ä½“ä½ç½®
            location = self._find_location(code, m, functions)
            if location:
                lines.append(f"â”‚")
                lines.append(f"â”‚  ğŸ“ Location:")
                lines.append(f"â”‚     Module:   {module_name or 'Unknown'}")
                if location.get('function'):
                    lines.append(f"â”‚     Function: {location['function']}")
                if location.get('line'):
                    lines.append(f"â”‚     Line:     {location['line']}")
                if location.get('code_snippet'):
                    lines.append(f"â”‚     Code:     {location['code_snippet'][:60]}...")

            # å»ºè®®
            if m.recommendation:
                lines.append(f"â”‚")
                lines.append(f"â”‚  ğŸ’¡ Recommendation:")
                # æ¢è¡Œå¤„ç†é•¿æ–‡æœ¬
                rec_lines = m.recommendation.split('\n')
                for rec_line in rec_lines[:3]:
                    if rec_line.strip():
                        lines.append(f"â”‚     {rec_line.strip()[:65]}")

            # å»ºè®®çš„ Spec æ£€æŸ¥
            if m.suggested_checks:
                lines.append(f"â”‚")
                lines.append(f"â”‚  âœ… Suggested Spec Checks:")
                for check in m.suggested_checks[:2]:
                    lines.append(f"â”‚     â€¢ {check}")

            lines.append(f"â”‚")
            lines.append(f"â””{'â”€' * 68}")

        lines.append("")
        lines.append("=" * 70)
        lines.append("ğŸ’¡ NOTE: Formal verification passing does NOT guarantee security.")
        lines.append("   Please manually review all findings above.")
        lines.append("=" * 70)
        lines.append("")

        return "\n".join(lines)

    def _extract_module_name(self, code: str) -> Optional[str]:
        """ä»ä»£ç ä¸­æå–æ¨¡å—å"""
        match = re.search(r'module\s+(\w+::[\w:]+)\s*\{', code)
        if match:
            return match.group(1)
        return None

    def _extract_functions(self, code: str) -> List[Dict]:
        """ä»ä»£ç ä¸­æå–å‡½æ•°åˆ—è¡¨"""
        functions = []
        pattern = r'(public\s+)?fun\s+(\w+)\s*[<\(]'

        for i, line in enumerate(code.split('\n'), 1):
            match = re.search(pattern, line)
            if match:
                functions.append({
                    'name': match.group(2),
                    'line': i,
                    'is_public': match.group(1) is not None,
                    'code': line.strip()
                })
        return functions

    def _find_location(self, code: str, match: PatternMatch, functions: List[Dict]) -> Optional[Dict]:
        """æ ¹æ®åŒ¹é…ç»“æœæ‰¾åˆ°ä»£ç ä¸­çš„å…·ä½“ä½ç½®"""
        result = {}
        code_lines = code.split('\n')

        # 0. é¦–å…ˆå°è¯•ä»æ ‡é¢˜/æè¿°ä¸­æå–å‡½æ•°åï¼Œä¼˜å…ˆå®šä½åˆ°å‡½æ•°
        description = getattr(match, 'description', '') or ''
        title_lower = match.title.lower()
        desc_lower = description.lower()

        # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°ååœ¨æ ‡é¢˜æˆ–æè¿°ä¸­è¢«æåŠ
        for func in functions:
            func_name = func['name'].lower()
            if func_name in title_lower or func_name in desc_lower:
                result['function'] = func['name']
                result['line'] = func['line']
                result['code_snippet'] = func['code']
                result['code_context'] = self._extract_code_context(code, func['line'])
                return result  # ç›´æ¥è¿”å›å‡½æ•°ä½ç½®

        # å¦‚æœæœ‰è¡Œå·æç¤ºï¼Œç›´æ¥ä½¿ç”¨
        if match.line_hints:
            line_num = match.line_hints[0]
            if 0 < line_num <= len(code_lines):
                result['line'] = line_num
                result['code_snippet'] = code_lines[line_num - 1].strip()
                result['code_context'] = self._extract_code_context(code, line_num)

        # å°è¯•é€šè¿‡ matched_cues æ‰¾åˆ°ä½ç½®
        if not result:
            # ä¼˜å…ˆé€‰æ‹©åœ¨å‡½æ•°å†…éƒ¨çš„åŒ¹é…ï¼Œè€Œä¸æ˜¯ struct å®šä¹‰
            candidates = []
            for cue in match.matched_cues:
                if cue == "semantic_match":
                    continue
                for i, line in enumerate(code_lines, 1):
                    if cue.lower() in line.lower():
                        # æ£€æŸ¥æ˜¯å¦åœ¨ struct å®šä¹‰ä¸­ï¼ˆè·³è¿‡ struct å­—æ®µï¼‰
                        is_in_struct = self._is_in_struct_definition(code_lines, i)
                        # æ‰¾åˆ°åŒ…å«è¿™è¡Œçš„å‡½æ•°
                        containing_func = None
                        for func in reversed(functions):
                            if func['line'] <= i:
                                containing_func = func['name']
                                break

                        candidates.append({
                            'line': i,
                            'code_snippet': line.strip(),
                            'function': containing_func,
                            'is_in_struct': is_in_struct,
                            'priority': 0 if is_in_struct else (2 if containing_func else 1)
                        })

            # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šå‡½æ•°å†…éƒ¨ > æ¨¡å—çº§ > struct å†…éƒ¨
            if candidates:
                candidates.sort(key=lambda x: x['priority'], reverse=True)
                best = candidates[0]
                result['line'] = best['line']
                result['code_snippet'] = best['code_snippet']
                result['code_context'] = self._extract_code_context(code, best['line'])
                if best['function']:
                    result['function'] = best['function']

        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°å‡½æ•°ï¼Œå°è¯•åŒ¹é…æ ‡é¢˜ä¸­çš„å‡½æ•°å
        if not result.get('function'):
            for func in functions:
                if func['name'].lower() in match.title.lower():
                    result['function'] = func['name']
                    if not result.get('line'):
                        result['line'] = func['line']
                        result['code_snippet'] = func['code']
                        result['code_context'] = self._extract_code_context(code, func['line'])
                    break

        return result if result else None

    def _is_in_struct_definition(self, code_lines: List[str], line_num: int) -> bool:
        """æ£€æŸ¥æŸè¡Œæ˜¯å¦åœ¨ struct å®šä¹‰å†…éƒ¨"""
        # å‘ä¸ŠæŸ¥æ‰¾ï¼Œçœ‹æ˜¯å¦åœ¨ struct {...} å—å†…
        brace_count = 0
        for i in range(line_num - 1, -1, -1):
            line = code_lines[i]
            brace_count += line.count('}') - line.count('{')
            if 'struct ' in line and '{' in line:
                # æ‰¾åˆ°äº† struct å®šä¹‰çš„å¼€å§‹
                if brace_count <= 0:
                    return True
                break
            if 'fun ' in line or 'public fun ' in line:
                # åœ¨å‡½æ•°å†…ï¼Œä¸æ˜¯ struct
                return False
        return False

    def _extract_code_context(self, code: str, line: int, context_lines: int = 3) -> str:
        """
        æå–æŒ‡å®šè¡Œçš„å‰åä¸Šä¸‹æ–‡

        Args:
            code: å®Œæ•´ä»£ç 
            line: ç›®æ ‡è¡Œå· (1-based)
            context_lines: å‰åå„å–å‡ è¡Œ (é»˜è®¤3)

        Returns:
            å¸¦è¡Œå·çš„ä»£ç ç‰‡æ®µï¼Œç›®æ ‡è¡Œç”¨ â†’ æ ‡è®°
        """
        lines = code.split('\n')
        start = max(0, line - 1 - context_lines)
        end = min(len(lines), line + context_lines)

        result = []
        for i in range(start, end):
            line_num = i + 1
            prefix = "â†’ " if line_num == line else "  "  # æ ‡è®°ç›®æ ‡è¡Œ
            result.append(f"{line_num:4d} {prefix}{lines[i]}")

        return '\n'.join(result)

    def generate_report_file(
        self,
        code: str,
        report: ScanReport,
        output_dir: str = "reports/security_audits",
        source_tag: Optional[str] = None,
        module_name: Optional[str] = None,
    ) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„å®‰å…¨å®¡è®¡æŠ¥å‘Šæ–‡ä»¶

        Args:
            code: æºä»£ç 
            report: æ‰«ææŠ¥å‘Š
            output_dir: è¾“å‡ºç›®å½•
            source_tag: é¢†åŸŸæ ‡ç­¾
            module_name: æ¨¡å—å (å¯é€‰ï¼Œè‡ªåŠ¨æå–)

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        base_dir = Path(__file__).resolve().parents[2]
        output_path = base_dir / output_dir
        output_path.mkdir(parents=True, exist_ok=True)

        # æå–æ¨¡å—å
        if not module_name:
            module_name = self._extract_module_name(code) or "unknown"

        # æå–å‡½æ•°åˆ—è¡¨
        functions = self._extract_functions(code)

        # ç”Ÿæˆæ—¶é—´æˆ³å’Œæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_module_name = module_name.replace("::", "_").replace("/", "_")
        filename = f"{safe_module_name}_{timestamp}.md"
        filepath = output_path / filename

        # å‡†å¤‡æ¨¡æ¿æ•°æ®
        severity_emoji = {
            "critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡",
            "low": "ğŸŸ¢", "advisory": "ğŸ”µ"
        }

        # ç»Ÿè®¡ä¸¥é‡æ€§åˆ†å¸ƒ
        severity_dist = {}
        for m in report.matches:
            severity_dist[m.severity] = severity_dist.get(m.severity, 0) + 1

        # å¤„ç†æ¯ä¸ªå‘ç°é¡¹
        findings = []
        sorted_matches = sorted(
            report.matches,
            key=lambda m: SEVERITY_WEIGHTS.get(m.severity, 0),
            reverse=True
        )

        for m in sorted_matches:
            location = self._find_location(code, m, functions)
            findings.append({
                "pattern_id": m.pattern_id,
                "title": m.title,
                "severity": m.severity,
                "severity_emoji": severity_emoji.get(m.severity, "âšª"),
                "confidence": int(m.confidence * 100),
                "tags": m.issue_tags,
                "module": module_name,
                "function": location.get('function') if location else None,
                "line": location.get('line') if location else None,
                "code_context": location.get('code_context', '') if location else '',
                "recommendation": m.recommendation,
                "suggested_checks": m.suggested_checks,
            })

        # å°è¯•ä½¿ç”¨ Jinja2 æ¨¡æ¿
        template_path = base_dir / "templates" / "security_report.md.j2"
        if JINJA2_AVAILABLE and template_path.exists():
            env = Environment(loader=FileSystemLoader(str(base_dir / "templates")))
            template = env.get_template("security_report.md.j2")
            content = template.render(
                module_name=module_name,
                domain_tag=source_tag or "general",
                risk_score=report.risk_score,
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                total_issues=len(report.matches),
                severity_dist=severity_dist,
                severity_emoji=severity_emoji,
                findings=findings,
            )
        else:
            # é™çº§ï¼šæ‰‹åŠ¨ç”Ÿæˆ Markdown
            content = self._generate_markdown_report(
                module_name=module_name,
                source_tag=source_tag,
                report=report,
                findings=findings,
                severity_dist=severity_dist,
                severity_emoji=severity_emoji,
            )

        # å†™å…¥æ–‡ä»¶
        filepath.write_text(content, encoding="utf-8")
        return str(filepath)

    def _generate_markdown_report(
        self,
        module_name: str,
        source_tag: Optional[str],
        report: ScanReport,
        findings: List[Dict],
        severity_dist: Dict[str, int],
        severity_emoji: Dict[str, str],
    ) -> str:
        """æ‰‹åŠ¨ç”Ÿæˆ Markdown æŠ¥å‘Š (é™çº§æ–¹æ¡ˆ)"""
        lines = [
            "# Security Audit Report",
            "",
            "## Overview",
            "",
            "| Field | Value |",
            "|-------|-------|",
            f"| **Module** | `{module_name}` |",
            f"| **Domain** | {source_tag or 'general'} |",
            f"| **Risk Score** | {report.risk_score}/100 |",
            f"| **Scan Time** | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |",
            f"| **Issues Found** | {len(report.matches)} |",
            "",
            "## Severity Distribution",
            "",
        ]

        for sev in ["critical", "high", "medium", "low", "advisory"]:
            if sev in severity_dist:
                lines.append(f"- {severity_emoji.get(sev, 'âšª')} **{sev.upper()}**: {severity_dist[sev]}")

        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## Findings")
        lines.append("")

        for i, f in enumerate(findings, 1):
            lines.append(f"### {i}. {f['severity_emoji']} [{f['severity'].upper()}] {f['title']}")
            lines.append("")
            lines.append("| Field | Value |")
            lines.append("|-------|-------|")
            lines.append(f"| **ID** | `{f['pattern_id']}` |")
            lines.append(f"| **Confidence** | {f['confidence']}% |")
            tags_str = ', '.join(f['tags']) if f['tags'] else 'N/A'
            lines.append(f"| **Tags** | {tags_str} |")
            lines.append("")
            lines.append("#### Location")
            lines.append("")
            lines.append(f"- **Module**: `{f['module']}`")
            lines.append(f"- **Function**: `{f['function'] or 'N/A'}`")
            lines.append(f"- **Line**: {f['line'] or 'N/A'}")
            lines.append("")
            lines.append("#### Code Context")
            lines.append("")
            lines.append("```move")
            lines.append(f['code_context'] if f['code_context'] else '(Unable to extract context)')
            lines.append("```")
            lines.append("")
            lines.append("#### Recommendation")
            lines.append("")
            lines.append(f"{f['recommendation']}")
            lines.append("")
            if f['suggested_checks']:
                lines.append("#### Suggested Spec Checks")
                lines.append("")
                for check in f['suggested_checks']:
                    lines.append(f"- `{check}`")
                lines.append("")
            lines.append("---")
            lines.append("")

        lines.append("## Disclaimer")
        lines.append("")
        lines.append("> Formal verification passing does NOT guarantee security.")
        lines.append("> Please manually review all findings above.")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*Generated by AutoSpec Security Scanner*")

        return "\n".join(lines)

    def generate_audit_package(
        self,
        code: str,
        report: "ScanReport",
        verified_spec: str,
        reviewed_report: Optional[object] = None,
        output_dir: str = "reports/security_audits",
        source_tag: Optional[str] = None,
        module_name: Optional[str] = None,
        verification_rounds: int = 0,
    ) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„å®¡è®¡åŒ…ï¼ˆç›®å½•ï¼‰ï¼ŒåŒ…å«ï¼š
        1. security_report.md - å®‰å…¨å®¡è®¡æŠ¥å‘Š
        2. verified_spec.move - å½¢å¼åŒ–éªŒè¯é€šè¿‡çš„ä»£ç 

        Args:
            code: åŸå§‹ä»£ç 
            report: æ‰«ææŠ¥å‘Š
            verified_spec: å½¢å¼åŒ–éªŒè¯é€šè¿‡çš„ä»£ç 
            reviewed_report: å®¡æ ¸åçš„æŠ¥å‘Š (å¯é€‰ï¼ŒåŒ…å«è¦†ç›–åˆ†æ)
            output_dir: è¾“å‡ºæ ¹ç›®å½•
            source_tag: é¢†åŸŸæ ‡ç­¾
            module_name: æ¨¡å—å
            verification_rounds: éªŒè¯è½®æ¬¡

        Returns:
            ç”Ÿæˆçš„å®¡è®¡åŒ…ç›®å½•è·¯å¾„
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        base_dir = Path(__file__).resolve().parents[2]
        audits_base = base_dir / output_dir

        # æå–æ¨¡å—å
        if not module_name:
            module_name = self._extract_module_name(code) or "unknown"

        # ç”Ÿæˆæ—¶é—´æˆ³å’Œç›®å½•å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_module_name = module_name.replace("::", "_").replace("/", "_")
        package_name = f"{safe_module_name}_{timestamp}"
        package_path = audits_base / package_name
        package_path.mkdir(parents=True, exist_ok=True)

        # 1. ä¿å­˜å½¢å¼åŒ–éªŒè¯ä»£ç 
        spec_file = package_path / "verified_spec.move"
        spec_file.write_text(verified_spec, encoding="utf-8")

        # 2. ç”Ÿæˆå¢å¼ºç‰ˆå®¡è®¡æŠ¥å‘Š
        report_content = self._generate_enhanced_report(
            code=code,
            report=report,
            verified_spec=verified_spec,
            reviewed_report=reviewed_report,
            module_name=module_name,
            source_tag=source_tag,
            verification_rounds=verification_rounds,
        )
        report_file = package_path / "security_report.md"
        report_file.write_text(report_content, encoding="utf-8")

        return str(package_path)

    def _generate_enhanced_report(
        self,
        code: str,
        report: "ScanReport",
        verified_spec: str,
        reviewed_report: Optional[object],
        module_name: str,
        source_tag: Optional[str],
        verification_rounds: int,
    ) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆå®¡è®¡æŠ¥å‘Šï¼ˆåŒ…å«è¦†ç›–åˆ†æï¼‰"""

        severity_emoji = {
            "critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡",
            "low": "ğŸŸ¢", "advisory": "ğŸ”µ"
        }

        # ç»Ÿè®¡ä¸¥é‡æ€§åˆ†å¸ƒ
        severity_dist = {}
        for m in report.matches:
            severity_dist[m.severity] = severity_dist.get(m.severity, 0) + 1

        # æå–å‡½æ•°åˆ—è¡¨
        functions = self._extract_functions(code)

        # æå–specå‡½æ•°
        spec_functions = []
        if verified_spec:
            patterns = [
                r'fun\s+(\w+_spec)\s*[<(]',
                r'spec\s+fun\s+(\w+)',
            ]
            for pattern in patterns:
                matches = re.findall(pattern, verified_spec)
                spec_functions.extend(matches)
            spec_functions = list(set(spec_functions))

        # è·å–è¦†ç›–ä¿¡æ¯
        coverage_summary = None
        fully_covered = []
        partially_covered = []
        not_covered = []
        adjusted_risk_score = report.risk_score

        if reviewed_report and hasattr(reviewed_report, 'get_coverage_summary'):
            coverage_summary = reviewed_report.get_coverage_summary()
            adjusted_risk_score = reviewed_report.get_filtered_risk_score()
            fully_covered = getattr(reviewed_report, 'fully_covered', [])
            partially_covered = getattr(reviewed_report, 'partially_covered', [])
            not_covered = getattr(reviewed_report, 'not_covered', [])

        # é¢„å…ˆè¿‡æ»¤æ— æ³•å®šä½çš„æ¼æ´ï¼ˆpartially_covered å’Œ not_coveredï¼‰
        valid_not_covered_count = 0
        valid_partial_count = 0

        def _has_valid_location(match) -> bool:
            """æ£€æŸ¥æ¼æ´æ˜¯å¦æœ‰æœ‰æ•ˆçš„ä»£ç ä½ç½®"""
            loc = self._find_location(code, match, functions)
            return (
                loc and
                loc.get('line', 0) > 1 and
                loc.get('code_context') and
                'module ' not in loc.get('code_context', '').split('\n')[0]
            )

        if partially_covered:
            for r in partially_covered:
                if _has_valid_location(r.original_match):
                    valid_partial_count += 1

        if not_covered:
            for r in not_covered:
                if _has_valid_location(r.original_match):
                    valid_not_covered_count += 1

        # è®¡ç®—å®é™…æœ‰æ•ˆçš„æ¼æ´æ•°é‡
        actual_issues = len(fully_covered) + valid_partial_count + valid_not_covered_count

        # ä½¿ç”¨è¿‡æ»¤åçš„å®é™…æ¼æ´æ•°é‡
        issues_display = actual_issues if coverage_summary else len(report.matches)

        # è®¡ç®—é£é™©ç­‰çº§
        def get_risk_level(score: int) -> str:
            if score >= 80:
                return "ğŸ”´ Critical"
            elif score >= 60:
                return "ğŸŸ  High"
            elif score >= 40:
                return "ğŸŸ¡ Medium"
            elif score >= 20:
                return "ğŸŸ¢ Low"
            else:
                return "âœ… Minimal"

        risk_level = get_risk_level(adjusted_risk_score)

        lines = [
            "# Security Audit Report",
            "",
            "## ğŸ“‹ Overview",
            "",
            "| Field | Value |",
            "|-------|-------|",
            f"| **Module** | `{module_name}` |",
            f"| **Domain** | {source_tag or 'general'} |",
            f"| **Risk Level** | {risk_level} ({adjusted_risk_score}/100) |",
            f"| **Verification Rounds** | {verification_rounds} |",
            f"| **Scan Time** | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |",
            f"| **Valid Issues** | {issues_display} |",
            "",
        ]

        # ä¸¥é‡æ€§åˆ†å¸ƒ (åªç»Ÿè®¡æœ‰æ•ˆæ¼æ´)
        if coverage_summary:
            # é‡æ–°è®¡ç®—åªåŒ…å«æœ‰æ•ˆæ¼æ´çš„ä¸¥é‡æ€§åˆ†å¸ƒ
            valid_severity_dist = {}
            for r in fully_covered:
                sev = r.original_match.severity
                valid_severity_dist[sev] = valid_severity_dist.get(sev, 0) + 1
            # å¯¹äº partially_coveredï¼Œåªè®¡å…¥æœ‰æ•ˆä½ç½®çš„
            for r in partially_covered:
                if _has_valid_location(r.original_match):
                    sev = r.original_match.severity
                    valid_severity_dist[sev] = valid_severity_dist.get(sev, 0) + 1
            # å¯¹äº not_coveredï¼Œåªè®¡å…¥æœ‰æ•ˆä½ç½®çš„
            for r in not_covered:
                if _has_valid_location(r.original_match):
                    sev = r.original_match.severity
                    valid_severity_dist[sev] = valid_severity_dist.get(sev, 0) + 1
            severity_dist = valid_severity_dist

        lines.append("## ğŸ“Š Severity Distribution")
        lines.append("")
        for sev in ["critical", "high", "medium", "low", "advisory"]:
            if sev in severity_dist:
                lines.append(f"- {severity_emoji.get(sev, 'âšª')} **{sev.upper()}**: {severity_dist[sev]}")
        lines.append("")

        # å½¢å¼åŒ–éªŒè¯æ‘˜è¦
        lines.append("---")
        lines.append("")
        lines.append("## âœ… Formal Verification Summary")
        lines.append("")
        lines.append(f"**Status**: {'âœ… PASSED' if verified_spec else 'âŒ FAILED'}")
        lines.append(f"**Rounds to Pass**: {verification_rounds}")
        lines.append("")
        if spec_functions:
            lines.append("**Verified Spec Functions**:")
            for func in spec_functions:
                lines.append(f"- `{func}`")
            lines.append("")
        lines.append("> ğŸ“ See `verified_spec.move` for the complete verified specification code.")
        lines.append("")

        # Specè¦†ç›–åˆ†æ
        if coverage_summary:
            lines.append("---")
            lines.append("")
            lines.append("## ğŸ›¡ï¸ Spec Coverage Analysis")
            lines.append("")
            lines.append("| Coverage Status | Count | Risk Impact |")
            lines.append("|-----------------|-------|-------------|")
            lines.append(f"| âœ… Fully Covered | {len(fully_covered)} | -90% risk |")
            lines.append(f"| ğŸ”¶ Partially Covered | {valid_partial_count} | -50% risk |")
            lines.append(f"| âŒ Not Covered | {valid_not_covered_count} | Full risk |")
            lines.append("")

            # é£é™©è¯„åˆ†æ˜ç»†
            lines.append("### ğŸ“Š Risk Score Breakdown")
            lines.append("")
            lines.append("| Vulnerability | Severity | Base Score | Coverage | Final Score |")
            lines.append("|--------------|----------|------------|----------|-------------|")

            # è®¡ç®—æ¯ä¸ªæ¼æ´çš„åˆ†æ•°
            severity_base = {"critical": 40, "high": 25, "medium": 15, "low": 8, "advisory": 4}

            for r in fully_covered:
                m = r.original_match
                base = severity_base.get(m.severity, 10)
                final = int(base * 0.1)  # -90%
                lines.append(f"| {m.title[:35]}{'...' if len(m.title) > 35 else ''} | {m.severity.upper()} | {base} | âœ… -90% | {final} |")

            for r in partially_covered:
                m = r.original_match
                if _has_valid_location(m):
                    base = severity_base.get(m.severity, 10)
                    final = int(base * 0.5)  # -50%
                    lines.append(f"| {m.title[:35]}{'...' if len(m.title) > 35 else ''} | {m.severity.upper()} | {base} | ğŸ”¶ -50% | {final} |")

            for r in not_covered:
                m = r.original_match
                if _has_valid_location(m):
                    base = severity_base.get(m.severity, 10)
                    lines.append(f"| {m.title[:35]}{'...' if len(m.title) > 35 else ''} | {m.severity.upper()} | {base} | âŒ 0% | {base} |")

            lines.append("")
            lines.append(f"**Total Risk Score: {adjusted_risk_score}/100** ({risk_level})")
            lines.append("")
            lines.append("> ğŸ’¡ Scoring: CRITICAL=40, HIGH=25, MEDIUM=15, LOW=8, ADVISORY=4. Covered by spec reduces risk.")
            lines.append("")

            # è¯¦ç»†è¦†ç›–åˆ†æ
            if fully_covered:
                lines.append("### âœ… Fully Covered by Spec")
                lines.append("")
                lines.append("> These vulnerabilities are addressed by the verified specification.")
                lines.append("")
                for r in fully_covered:
                    m = r.original_match
                    coverage = r.spec_coverage
                    lines.append(f"**{m.pattern_id}: {m.title}**")
                    lines.append(f"- Severity: {severity_emoji.get(m.severity, 'âšª')} {m.severity.upper()}")
                    if coverage and coverage.coverage_evidence != "None":
                        lines.append(f"- Evidence: `{coverage.coverage_evidence[:100]}`")
                    lines.append("")

            # Partially Covered - åŒæ ·è¿‡æ»¤æ— æ•ˆä½ç½®
            if partially_covered:
                valid_partial = []
                partial_skipped = 0
                for r in partially_covered:
                    m = r.original_match
                    location = self._find_location(code, m, functions)
                    has_valid_location = (
                        location and
                        location.get('line', 0) > 1 and
                        location.get('code_context') and
                        'module ' not in location.get('code_context', '').split('\n')[0]
                    )
                    if has_valid_location:
                        valid_partial.append((r, location))
                    else:
                        partial_skipped += 1

                if valid_partial:
                    lines.append("### ğŸ”¶ Partially Covered by Spec")
                    lines.append("")
                    lines.append("> These vulnerabilities are partially addressed. Manual review recommended.")
                    lines.append("")

                    for r, location in valid_partial:
                        m = r.original_match
                        coverage = r.spec_coverage

                        lines.append(f"#### {m.pattern_id}: {m.title}")
                        lines.append("")
                        lines.append(f"| Field | Value |")
                        lines.append(f"|-------|-------|")
                        lines.append(f"| Severity | {severity_emoji.get(m.severity, 'âšª')} {m.severity.upper()} |")
                        lines.append(f"| Line | {location.get('line')} |")
                        lines.append("")
                        lines.append("**Code Context**:")
                        lines.append("```move")
                        lines.append(location['code_context'])
                        lines.append("```")
                        lines.append("")

                        # é£é™©åˆ†æ
                        desc = getattr(m, 'description', None) or ""
                        if desc and desc.strip():
                            lines.append("**Risk Analysis**:")
                            lines.append(f"> {desc[:500]}")
                            lines.append("")

                        # Spec è¦†ç›–è¯´æ˜
                        if coverage:
                            lines.append(f"**Spec Coverage**: {coverage.explanation}")
                            if coverage.coverage_evidence and coverage.coverage_evidence != "None":
                                lines.append(f"- Evidence: `{coverage.coverage_evidence[:100]}`")
                        lines.append("")

                        # ä¿®å¤å»ºè®®
                        if m.recommendation:
                            lines.append("**Recommendation**:")
                            lines.append(f"> {m.recommendation}")
                            lines.append("")

                if partial_skipped > 0:
                    lines.append(f"> â„¹ï¸ {partial_skipped} partially covered findings were filtered out (could not locate in code).")
                    lines.append("")

            if not_covered:
                # è¿‡æ»¤æ‰æ— æ³•å®šä½åˆ°ä»£ç çš„æ¼æ´
                valid_not_covered = []
                skipped_count = 0
                for r in not_covered:
                    m = r.original_match
                    location = self._find_location(code, m, functions)

                    # æ£€æŸ¥ä½ç½®æ˜¯å¦æœ‰æ•ˆï¼ˆline > 1 ä¸”ä¸æ˜¯æŒ‡å‘æ¨¡å—å£°æ˜ï¼‰
                    has_valid_location = (
                        location and
                        location.get('line', 0) > 1 and
                        location.get('code_context') and
                        'module ' not in location.get('code_context', '').split('\n')[0]
                    )

                    if has_valid_location:
                        valid_not_covered.append((r, location))
                    else:
                        skipped_count += 1

                if valid_not_covered:
                    lines.append("### âŒ Not Covered by Spec (Remaining Risks)")
                    lines.append("")
                    lines.append("> âš ï¸ These vulnerabilities are NOT addressed by the specification. Manual review required!")
                    lines.append("")

                    for r, location in valid_not_covered:
                        m = r.original_match
                        coverage = r.spec_coverage

                        lines.append(f"#### {m.pattern_id}: {m.title}")
                        lines.append("")
                        lines.append(f"| Field | Value |")
                        lines.append(f"|-------|-------|")
                        lines.append(f"| Severity | {severity_emoji.get(m.severity, 'âšª')} {m.severity.upper()} |")
                        lines.append(f"| Line | {location.get('line')} |")
                        lines.append("")
                        lines.append("**Code Context**:")
                        lines.append("```move")
                        lines.append(location['code_context'])
                        lines.append("```")
                        lines.append("")

                        # é£é™©åˆ†æ - è§£é‡Šä¸ºä»€ä¹ˆè¿™æ˜¯ä¸€ä¸ªé£é™©
                        desc = getattr(m, 'description', None) or ""
                        if desc and desc.strip():
                            lines.append("**Risk Analysis**:")
                            lines.append(f"> {desc[:500]}")
                            lines.append("")

                        # ä¿®å¤å»ºè®®
                        if m.recommendation:
                            lines.append("**Recommendation**:")
                            lines.append(f"> {m.recommendation}")
                            lines.append("")

                        if m.suggested_checks:
                            lines.append("**Suggested Spec Checks**:")
                            for check in m.suggested_checks:
                                lines.append(f"- `{check}`")
                            lines.append("")

                if skipped_count > 0:
                    lines.append(f"> â„¹ï¸ {skipped_count} findings were filtered out (could not locate in code).")
                    lines.append("")
        else:
            # æ²¡æœ‰è¦†ç›–åˆ†æï¼Œä½¿ç”¨åŸå§‹findings
            lines.append("---")
            lines.append("")
            lines.append("## âš ï¸ Findings")
            lines.append("")

            sorted_matches = sorted(
                report.matches,
                key=lambda m: SEVERITY_WEIGHTS.get(m.severity, 0),
                reverse=True
            )

            for i, m in enumerate(sorted_matches, 1):
                location = self._find_location(code, m, functions)
                lines.append(f"### {i}. {severity_emoji.get(m.severity, 'âšª')} [{m.severity.upper()}] {m.title}")
                lines.append("")
                lines.append(f"| Field | Value |")
                lines.append(f"|-------|-------|")
                lines.append(f"| ID | `{m.pattern_id}` |")
                lines.append(f"| Confidence | {int(m.confidence * 100)}% |")
                if location:
                    lines.append(f"| Line | {location.get('line', 'N/A')} |")
                lines.append("")
                if location and location.get('code_context'):
                    lines.append("**Code Context**:")
                    lines.append("```move")
                    lines.append(location['code_context'])
                    lines.append("```")
                    lines.append("")
                lines.append(f"**Recommendation**: {m.recommendation}")
                lines.append("")
                lines.append("---")
                lines.append("")

        # Disclaimer
        lines.append("---")
        lines.append("")
        lines.append("## âš ï¸ Disclaimer")
        lines.append("")
        lines.append("> Formal verification passing does NOT guarantee complete security.")
        lines.append("> - **Fully Covered** issues have specification guards but may have implementation gaps.")
        lines.append("> - **Not Covered** issues require additional specification or manual code review.")
        lines.append("> - Always perform comprehensive security audits before production deployment.")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*Generated by AutoSpec Security Scanner*")

        return "\n".join(lines)


# ==============================================================================
# ä¾¿æ·å‡½æ•° (å‘åå…¼å®¹)
# ==============================================================================

def load_patterns(dataset_path: Optional[str] = None) -> List[Dict]:
    """åŠ è½½å¤–éƒ¨æ¨¡å¼ (å‘åå…¼å®¹)"""
    default_path = Path(__file__).resolve().parents[2] / "reports" / "datasets" / "security_patterns.jsonl"
    path = Path(dataset_path) if dataset_path else default_path
    if not path.exists():
        return []
    patterns: List[Dict] = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                patterns.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return patterns


def scan_code_for_patterns(
    code: str,
    patterns: List[Dict],
    module_hint: Optional[str] = None,
    function_hint: Optional[str] = None,
) -> List[Dict]:
    """åŸºäºç®€å•å…³é”®è¯/å‡½æ•°å cue çš„åŒ¹é… (å‘åå…¼å®¹)"""
    results: List[Dict] = []
    code_lower = code.lower()
    for p in patterns:
        cues = p.get("detection_cues") or []
        matched = False

        if module_hint and p.get("module_path") and module_hint in str(p.get("module_path")):
            matched = True
        if function_hint and p.get("function") and function_hint in str(p.get("function")):
            matched = True

        for cue in cues:
            cue_l = str(cue).lower()
            if cue_l and cue_l in code_lower:
                matched = True
                break

        if matched:
            results.append({
                "id": p.get("id"),
                "title": p.get("title"),
                "severity": p.get("severity"),
                "issue_tags": p.get("issue_tags"),
                "recommendation": p.get("recommendation"),
            })
    return results
